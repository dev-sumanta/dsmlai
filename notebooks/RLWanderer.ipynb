{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reinforcement Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## -------------------------------------------------------------------------\n",
    "## Characteristics\n",
    "###  Agents\n",
    "###  States\n",
    "###  Rewards and Punishments\n",
    "### Agents work within environments to gain maximum rewards"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## -------------------------------------------------------------------------\n",
    "## What differentiates reinforcement learning\n",
    "### No training datasets\n",
    "### Interaction happens with environments used to depict real world scenarios\n",
    "### Environments may be 2D / 3D simulated worlds or game based scenarios\n",
    "### Broader because environments can be large in scale and may have many factors associated with them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "A simple example for Reinforcement Learning using table lookup Q-learning method.\n",
    "An agent \"o\" is on the left of a 1 dimensional world, the treasure is on the rightmost location.\n",
    "The agent will develop a strategy to find the treasur\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "np.random.seed(2)  # reproducible\n",
    "\n",
    "\n",
    "N_STATES = 6   # the length of the 1 dimensional world\n",
    "ACTIONS = ['left', 'right']     # available actions\n",
    "EPSILON = 0.9   # greedy policy\n",
    "ALPHA = 0.1     # learning rate\n",
    "GAMMA = 0.9    # discount factor\n",
    "MAX_EPISODES = 10   # maximum episodes\n",
    "FRESH_TIME = 0.3    # fresh time for one move\n",
    "\n",
    "\n",
    "def build_q_table(n_states, actions):\n",
    "    table = pd.DataFrame(\n",
    "        np.zeros((n_states, len(actions))),     # q_table initial values\n",
    "        columns=actions,    # actions's name\n",
    "    )\n",
    "    # print(table)    # show table\n",
    "    return table\n",
    "\n",
    "\n",
    "def choose_action(state, q_table):\n",
    "    # This is how to choose an action\n",
    "    # To get the possible actions for a state which will be between 0 and 5, we get that particular row\n",
    "    state_actions = q_table.iloc[state, :]\n",
    "    # We do a mix of non greedy and greedy steps\n",
    "    # if we have a ranrom condition met or the only state actions are 0, we make a random choice\n",
    "    if (np.random.uniform() > EPSILON) or ((state_actions == 0).all()):  \n",
    "        action_name = np.random.choice(ACTIONS)\n",
    "        print('\\n if state_actions is ', state_actions , ' and action_name chosen is ', action_name)\n",
    "    else:   # act greedy\n",
    "        # We take the action that has the max value\n",
    "        print('\\n else state_actions is ', state_actions , ' and state_actions.idxmax is ', state_actions.idxmax())\n",
    "        action_name = state_actions.idxmax()    # replace argmax to idxmax as argmax means a different function in newer version of pandas\n",
    "    print('\\naction chosen is ', action_name)\n",
    "    return action_name\n",
    "\n",
    "\n",
    "def get_env_feedback(S, A):\n",
    "    # This is how agent will interact with the environment\n",
    "    if A == 'right':    # move right\n",
    "        if S == N_STATES - 2:   # terminate\n",
    "            S_ = 'terminal'\n",
    "            R = 1\n",
    "        else:\n",
    "            S_ = S + 1\n",
    "            R = 0\n",
    "    else:   # move left\n",
    "        R = 0\n",
    "        if S == 0:\n",
    "            S_ = S  # reach the wall\n",
    "        else:\n",
    "            S_ = S - 1\n",
    "    return S_, R\n",
    "\n",
    "\n",
    "def update_env(S, episode, step_counter):\n",
    "    # We update the environment after each step\n",
    "    print('\\nS is {} episode is {} step_counter is {}'.format(S, episode, step_counter))\n",
    "    env_list = ['-']*(N_STATES-1) + ['T']   # '-----T' is our environment and we want to find the treasure T\n",
    "    if S == 'terminal':\n",
    "        interaction = 'Episode %s: total_steps = %s' % (episode+1, step_counter)\n",
    "        print('\\nupdate_env_if\\n','\\r{}'.format(interaction), end='')\n",
    "        time.sleep(2)\n",
    "        print('\\nupdate_env_if\\n', '\\r                                ', end='')\n",
    "    else:\n",
    "        env_list[S] = 'o'\n",
    "        interaction = ''.join(env_list)\n",
    "        print('\\nupdate_env_else\\n', '\\r{}'.format(interaction), end='')\n",
    "        time.sleep(FRESH_TIME)\n",
    "\n",
    "\n",
    "def rl():\n",
    "    # main part of RL loop\n",
    "    # First we build a q table for each of the six positions we can go right or left\n",
    "    q_table = build_q_table(N_STATES, ACTIONS)\n",
    "    for episode in range(MAX_EPISODES):\n",
    "        step_counter = 0\n",
    "        S = 0\n",
    "        is_terminated = False\n",
    "        # First time update the environment\n",
    "        update_env(S, episode, step_counter)\n",
    "        # And carry on till the goal is reached\n",
    "        while not is_terminated:\n",
    "            # First choose an Action\n",
    "            A = choose_action(S, q_table)\n",
    "            # Then get the feed back from the environment\n",
    "            S_, R = get_env_feedback(S, A)  # take action & get next state and reward\n",
    "            print('After get_env_feedback S_ is {} and R is {}'.format(S_, R))\n",
    "            # get the q table prediction\n",
    "            q_predict = q_table.loc[S, A]\n",
    "            print('q_predict is ', q_predict)\n",
    "            if S_ != 'terminal':\n",
    "                print('R is {} and GAMMA is {} and q_table.iloc[S_, :] is {} and q_target will be {}'.format(\n",
    "                R, GAMMA, q_table.iloc[S_,:], R + GAMMA * q_table.iloc[S_, :].max()))\n",
    "#                 q_target = R + GAMMA * q_table.iloc[S_, :].max()   # next state is not terminal\n",
    "            else:\n",
    "#                 q_target = R     # next state is terminal\n",
    "                is_terminated = True    # terminate this episode\n",
    "\n",
    "#             q_table.loc[S, A] += ALPHA * (q_target - q_predict)  # update\n",
    "            print('S is {} and A is {} and after update q_table.loc[S, A] is {:6f}'.format(S, A, q_table.loc[S, A]))\n",
    "            S = S_  # move to next state\n",
    "\n",
    "            update_env(S, episode, step_counter+1)\n",
    "            step_counter += 1\n",
    "    return q_table\n",
    "\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     q_table = rl()\n",
    "#     print('\\r\\nQ-table:\\n')\n",
    "#     print(q_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "S is 0 episode is 0 step_counter is 0\n",
      "\n",
      "update_env_else\n",
      "o----T\n",
      " if state_actions is  left     0.0\n",
      "right    0.0\n",
      "Name: 0, dtype: float64  and action_name chosen is  right\n",
      "\n",
      "action chosen is  right\n",
      "After get_env_feedback S_ is 1 and R is 0\n",
      "q_predict is  0.0\n",
      "R is 0 and GAMMA is 0.9 and q_table.iloc[S_, :] is left     0.0\n",
      "right    0.0\n",
      "Name: 1, dtype: float64 and q_target will be 0.0\n",
      "S is 0 and A is right and after update q_table.loc[S, A] is 0.000000\n",
      "\n",
      "S is 1 episode is 0 step_counter is 1\n",
      "\n",
      "update_env_else\n",
      "-o---T\n",
      " if state_actions is  left     0.0\n",
      "right    0.0\n",
      "Name: 1, dtype: float64  and action_name chosen is  right\n",
      "\n",
      "action chosen is  right\n",
      "After get_env_feedback S_ is 2 and R is 0\n",
      "q_predict is  0.0\n",
      "R is 0 and GAMMA is 0.9 and q_table.iloc[S_, :] is left     0.0\n",
      "right    0.0\n",
      "Name: 2, dtype: float64 and q_target will be 0.0\n",
      "S is 1 and A is right and after update q_table.loc[S, A] is 0.000000\n",
      "\n",
      "S is 2 episode is 0 step_counter is 2\n",
      "\n",
      "update_env_else\n",
      "--o--T\n",
      " if state_actions is  left     0.0\n",
      "right    0.0\n",
      "Name: 2, dtype: float64  and action_name chosen is  left\n",
      "\n",
      "action chosen is  left\n",
      "After get_env_feedback S_ is 1 and R is 0\n",
      "q_predict is  0.0\n",
      "R is 0 and GAMMA is 0.9 and q_table.iloc[S_, :] is left     0.0\n",
      "right    0.0\n",
      "Name: 1, dtype: float64 and q_target will be 0.0\n",
      "S is 2 and A is left and after update q_table.loc[S, A] is 0.000000\n",
      "\n",
      "S is 1 episode is 0 step_counter is 3\n",
      "\n",
      "update_env_else\n",
      "-o---T\n",
      " if state_actions is  left     0.0\n",
      "right    0.0\n",
      "Name: 1, dtype: float64  and action_name chosen is  right\n",
      "\n",
      "action chosen is  right\n",
      "After get_env_feedback S_ is 2 and R is 0\n",
      "q_predict is  0.0\n",
      "R is 0 and GAMMA is 0.9 and q_table.iloc[S_, :] is left     0.0\n",
      "right    0.0\n",
      "Name: 2, dtype: float64 and q_target will be 0.0\n",
      "S is 1 and A is right and after update q_table.loc[S, A] is 0.000000\n",
      "\n",
      "S is 2 episode is 0 step_counter is 4\n",
      "\n",
      "update_env_else\n",
      "--o--T\n",
      " if state_actions is  left     0.0\n",
      "right    0.0\n",
      "Name: 2, dtype: float64  and action_name chosen is  right\n",
      "\n",
      "action chosen is  right\n",
      "After get_env_feedback S_ is 3 and R is 0\n",
      "q_predict is  0.0\n",
      "R is 0 and GAMMA is 0.9 and q_table.iloc[S_, :] is left     0.0\n",
      "right    0.0\n",
      "Name: 3, dtype: float64 and q_target will be 0.0\n",
      "S is 2 and A is right and after update q_table.loc[S, A] is 0.000000\n",
      "\n",
      "S is 3 episode is 0 step_counter is 5\n",
      "\n",
      "update_env_else\n",
      "---o-T\n",
      " if state_actions is  left     0.0\n",
      "right    0.0\n",
      "Name: 3, dtype: float64  and action_name chosen is  right\n",
      "\n",
      "action chosen is  right\n",
      "After get_env_feedback S_ is 4 and R is 0\n",
      "q_predict is  0.0\n",
      "R is 0 and GAMMA is 0.9 and q_table.iloc[S_, :] is left     0.0\n",
      "right    0.0\n",
      "Name: 4, dtype: float64 and q_target will be 0.0\n",
      "S is 3 and A is right and after update q_table.loc[S, A] is 0.000000\n",
      "\n",
      "S is 4 episode is 0 step_counter is 6\n",
      "\n",
      "update_env_else\n",
      "----oT\n",
      " if state_actions is  left     0.0\n",
      "right    0.0\n",
      "Name: 4, dtype: float64  and action_name chosen is  left\n",
      "\n",
      "action chosen is  left\n",
      "After get_env_feedback S_ is 3 and R is 0\n",
      "q_predict is  0.0\n",
      "R is 0 and GAMMA is 0.9 and q_table.iloc[S_, :] is left     0.0\n",
      "right    0.0\n",
      "Name: 3, dtype: float64 and q_target will be 0.0\n",
      "S is 4 and A is left and after update q_table.loc[S, A] is 0.000000\n",
      "\n",
      "S is 3 episode is 0 step_counter is 7\n",
      "\n",
      "update_env_else\n",
      "---o-T\n",
      " if state_actions is  left     0.0\n",
      "right    0.0\n",
      "Name: 3, dtype: float64  and action_name chosen is  right\n",
      "\n",
      "action chosen is  right\n",
      "After get_env_feedback S_ is 4 and R is 0\n",
      "q_predict is  0.0\n",
      "R is 0 and GAMMA is 0.9 and q_table.iloc[S_, :] is left     0.0\n",
      "right    0.0\n",
      "Name: 4, dtype: float64 and q_target will be 0.0\n",
      "S is 3 and A is right and after update q_table.loc[S, A] is 0.000000\n",
      "\n",
      "S is 4 episode is 0 step_counter is 8\n",
      "\n",
      "update_env_else\n",
      "----oT\n",
      " if state_actions is  left     0.0\n",
      "right    0.0\n",
      "Name: 4, dtype: float64  and action_name chosen is  left\n",
      "\n",
      "action chosen is  left\n",
      "After get_env_feedback S_ is 3 and R is 0\n",
      "q_predict is  0.0\n",
      "R is 0 and GAMMA is 0.9 and q_table.iloc[S_, :] is left     0.0\n",
      "right    0.0\n",
      "Name: 3, dtype: float64 and q_target will be 0.0\n",
      "S is 4 and A is left and after update q_table.loc[S, A] is 0.000000\n",
      "\n",
      "S is 3 episode is 0 step_counter is 9\n",
      "\n",
      "update_env_else\n",
      "---o-T\n",
      " if state_actions is  left     0.0\n",
      "right    0.0\n",
      "Name: 3, dtype: float64  and action_name chosen is  right\n",
      "\n",
      "action chosen is  right\n",
      "After get_env_feedback S_ is 4 and R is 0\n",
      "q_predict is  0.0\n",
      "R is 0 and GAMMA is 0.9 and q_table.iloc[S_, :] is left     0.0\n",
      "right    0.0\n",
      "Name: 4, dtype: float64 and q_target will be 0.0\n",
      "S is 3 and A is right and after update q_table.loc[S, A] is 0.000000\n",
      "\n",
      "S is 4 episode is 0 step_counter is 10\n",
      "\n",
      "update_env_else\n",
      "----oT\n",
      " if state_actions is  left     0.0\n",
      "right    0.0\n",
      "Name: 4, dtype: float64  and action_name chosen is  left\n",
      "\n",
      "action chosen is  left\n",
      "After get_env_feedback S_ is 3 and R is 0\n",
      "q_predict is  0.0\n",
      "R is 0 and GAMMA is 0.9 and q_table.iloc[S_, :] is left     0.0\n",
      "right    0.0\n",
      "Name: 3, dtype: float64 and q_target will be 0.0\n",
      "S is 4 and A is left and after update q_table.loc[S, A] is 0.000000\n",
      "\n",
      "S is 3 episode is 0 step_counter is 11\n",
      "\n",
      "update_env_else\n",
      "---o-T\n",
      " if state_actions is  left     0.0\n",
      "right    0.0\n",
      "Name: 3, dtype: float64  and action_name chosen is  left\n",
      "\n",
      "action chosen is  left\n",
      "After get_env_feedback S_ is 2 and R is 0\n",
      "q_predict is  0.0\n",
      "R is 0 and GAMMA is 0.9 and q_table.iloc[S_, :] is left     0.0\n",
      "right    0.0\n",
      "Name: 2, dtype: float64 and q_target will be 0.0\n",
      "S is 3 and A is left and after update q_table.loc[S, A] is 0.000000\n",
      "\n",
      "S is 2 episode is 0 step_counter is 12\n",
      "\n",
      "update_env_else\n",
      "--o--T\n",
      " if state_actions is  left     0.0\n",
      "right    0.0\n",
      "Name: 2, dtype: float64  and action_name chosen is  right\n",
      "\n",
      "action chosen is  right\n",
      "After get_env_feedback S_ is 3 and R is 0\n",
      "q_predict is  0.0\n",
      "R is 0 and GAMMA is 0.9 and q_table.iloc[S_, :] is left     0.0\n",
      "right    0.0\n",
      "Name: 3, dtype: float64 and q_target will be 0.0\n",
      "S is 2 and A is right and after update q_table.loc[S, A] is 0.000000\n",
      "\n",
      "S is 3 episode is 0 step_counter is 13\n",
      "\n",
      "update_env_else\n",
      "---o-T\n",
      " if state_actions is  left     0.0\n",
      "right    0.0\n",
      "Name: 3, dtype: float64  and action_name chosen is  left\n",
      "\n",
      "action chosen is  left\n",
      "After get_env_feedback S_ is 2 and R is 0\n",
      "q_predict is  0.0\n",
      "R is 0 and GAMMA is 0.9 and q_table.iloc[S_, :] is left     0.0\n",
      "right    0.0\n",
      "Name: 2, dtype: float64 and q_target will be 0.0\n",
      "S is 3 and A is left and after update q_table.loc[S, A] is 0.000000\n",
      "\n",
      "S is 2 episode is 0 step_counter is 14\n",
      "\n",
      "update_env_else\n",
      "--o--T\n",
      " if state_actions is  left     0.0\n",
      "right    0.0\n",
      "Name: 2, dtype: float64  and action_name chosen is  right\n",
      "\n",
      "action chosen is  right\n",
      "After get_env_feedback S_ is 3 and R is 0\n",
      "q_predict is  0.0\n",
      "R is 0 and GAMMA is 0.9 and q_table.iloc[S_, :] is left     0.0\n",
      "right    0.0\n",
      "Name: 3, dtype: float64 and q_target will be 0.0\n",
      "S is 2 and A is right and after update q_table.loc[S, A] is 0.000000\n",
      "\n",
      "S is 3 episode is 0 step_counter is 15\n",
      "\n",
      "update_env_else\n",
      "---o-T\n",
      " if state_actions is  left     0.0\n",
      "right    0.0\n",
      "Name: 3, dtype: float64  and action_name chosen is  left\n",
      "\n",
      "action chosen is  left\n",
      "After get_env_feedback S_ is 2 and R is 0\n",
      "q_predict is  0.0\n",
      "R is 0 and GAMMA is 0.9 and q_table.iloc[S_, :] is left     0.0\n",
      "right    0.0\n",
      "Name: 2, dtype: float64 and q_target will be 0.0\n",
      "S is 3 and A is left and after update q_table.loc[S, A] is 0.000000\n",
      "\n",
      "S is 2 episode is 0 step_counter is 16\n",
      "\n",
      "update_env_else\n",
      "--o--T\n",
      " if state_actions is  left     0.0\n",
      "right    0.0\n",
      "Name: 2, dtype: float64  and action_name chosen is  left\n",
      "\n",
      "action chosen is  left\n",
      "After get_env_feedback S_ is 1 and R is 0\n",
      "q_predict is  0.0\n",
      "R is 0 and GAMMA is 0.9 and q_table.iloc[S_, :] is left     0.0\n",
      "right    0.0\n",
      "Name: 1, dtype: float64 and q_target will be 0.0\n",
      "S is 2 and A is left and after update q_table.loc[S, A] is 0.000000\n",
      "\n",
      "S is 1 episode is 0 step_counter is 17\n",
      "\n",
      "update_env_else\n",
      "-o---T\n",
      " if state_actions is  left     0.0\n",
      "right    0.0\n",
      "Name: 1, dtype: float64  and action_name chosen is  left\n",
      "\n",
      "action chosen is  left\n",
      "After get_env_feedback S_ is 0 and R is 0\n",
      "q_predict is  0.0\n",
      "R is 0 and GAMMA is 0.9 and q_table.iloc[S_, :] is left     0.0\n",
      "right    0.0\n",
      "Name: 0, dtype: float64 and q_target will be 0.0\n",
      "S is 1 and A is left and after update q_table.loc[S, A] is 0.000000\n",
      "\n",
      "S is 0 episode is 0 step_counter is 18\n",
      "\n",
      "update_env_else\n",
      "o----T\n",
      " if state_actions is  left     0.0\n",
      "right    0.0\n",
      "Name: 0, dtype: float64  and action_name chosen is  right\n",
      "\n",
      "action chosen is  right\n",
      "After get_env_feedback S_ is 1 and R is 0\n",
      "q_predict is  0.0\n",
      "R is 0 and GAMMA is 0.9 and q_table.iloc[S_, :] is left     0.0\n",
      "right    0.0\n",
      "Name: 1, dtype: float64 and q_target will be 0.0\n",
      "S is 0 and A is right and after update q_table.loc[S, A] is 0.000000\n",
      "\n",
      "S is 1 episode is 0 step_counter is 19\n",
      "\n",
      "update_env_else\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-o---T\n",
      " if state_actions is  left     0.0\n",
      "right    0.0\n",
      "Name: 1, dtype: float64  and action_name chosen is  right\n",
      "\n",
      "action chosen is  right\n",
      "After get_env_feedback S_ is 2 and R is 0\n",
      "q_predict is  0.0\n",
      "R is 0 and GAMMA is 0.9 and q_table.iloc[S_, :] is left     0.0\n",
      "right    0.0\n",
      "Name: 2, dtype: float64 and q_target will be 0.0\n",
      "S is 1 and A is right and after update q_table.loc[S, A] is 0.000000\n",
      "\n",
      "S is 2 episode is 0 step_counter is 20\n",
      "\n",
      "update_env_else\n",
      "--o--T\n",
      " if state_actions is  left     0.0\n",
      "right    0.0\n",
      "Name: 2, dtype: float64  and action_name chosen is  left\n",
      "\n",
      "action chosen is  left\n",
      "After get_env_feedback S_ is 1 and R is 0\n",
      "q_predict is  0.0\n",
      "R is 0 and GAMMA is 0.9 and q_table.iloc[S_, :] is left     0.0\n",
      "right    0.0\n",
      "Name: 1, dtype: float64 and q_target will be 0.0\n",
      "S is 2 and A is left and after update q_table.loc[S, A] is 0.000000\n",
      "\n",
      "S is 1 episode is 0 step_counter is 21\n",
      "\n",
      "update_env_else\n",
      "-o---T\n",
      " if state_actions is  left     0.0\n",
      "right    0.0\n",
      "Name: 1, dtype: float64  and action_name chosen is  right\n",
      "\n",
      "action chosen is  right\n",
      "After get_env_feedback S_ is 2 and R is 0\n",
      "q_predict is  0.0\n",
      "R is 0 and GAMMA is 0.9 and q_table.iloc[S_, :] is left     0.0\n",
      "right    0.0\n",
      "Name: 2, dtype: float64 and q_target will be 0.0\n",
      "S is 1 and A is right and after update q_table.loc[S, A] is 0.000000\n",
      "\n",
      "S is 2 episode is 0 step_counter is 22\n",
      "\n",
      "update_env_else\n",
      "--o--T\n",
      " if state_actions is  left     0.0\n",
      "right    0.0\n",
      "Name: 2, dtype: float64  and action_name chosen is  left\n",
      "\n",
      "action chosen is  left\n",
      "After get_env_feedback S_ is 1 and R is 0\n",
      "q_predict is  0.0\n",
      "R is 0 and GAMMA is 0.9 and q_table.iloc[S_, :] is left     0.0\n",
      "right    0.0\n",
      "Name: 1, dtype: float64 and q_target will be 0.0\n",
      "S is 2 and A is left and after update q_table.loc[S, A] is 0.000000\n",
      "\n",
      "S is 1 episode is 0 step_counter is 23\n",
      "\n",
      "update_env_else\n",
      "-o---T\n",
      " if state_actions is  left     0.0\n",
      "right    0.0\n",
      "Name: 1, dtype: float64  and action_name chosen is  left\n",
      "\n",
      "action chosen is  left\n",
      "After get_env_feedback S_ is 0 and R is 0\n",
      "q_predict is  0.0\n",
      "R is 0 and GAMMA is 0.9 and q_table.iloc[S_, :] is left     0.0\n",
      "right    0.0\n",
      "Name: 0, dtype: float64 and q_target will be 0.0\n",
      "S is 1 and A is left and after update q_table.loc[S, A] is 0.000000\n",
      "\n",
      "S is 0 episode is 0 step_counter is 24\n",
      "\n",
      "update_env_else\n",
      "o----T\n",
      " if state_actions is  left     0.0\n",
      "right    0.0\n",
      "Name: 0, dtype: float64  and action_name chosen is  right\n",
      "\n",
      "action chosen is  right\n",
      "After get_env_feedback S_ is 1 and R is 0\n",
      "q_predict is  0.0\n",
      "R is 0 and GAMMA is 0.9 and q_table.iloc[S_, :] is left     0.0\n",
      "right    0.0\n",
      "Name: 1, dtype: float64 and q_target will be 0.0\n",
      "S is 0 and A is right and after update q_table.loc[S, A] is 0.000000\n",
      "\n",
      "S is 1 episode is 0 step_counter is 25\n",
      "\n",
      "update_env_else\n",
      "-o---T\n",
      " if state_actions is  left     0.0\n",
      "right    0.0\n",
      "Name: 1, dtype: float64  and action_name chosen is  right\n",
      "\n",
      "action chosen is  right\n",
      "After get_env_feedback S_ is 2 and R is 0\n",
      "q_predict is  0.0\n",
      "R is 0 and GAMMA is 0.9 and q_table.iloc[S_, :] is left     0.0\n",
      "right    0.0\n",
      "Name: 2, dtype: float64 and q_target will be 0.0\n",
      "S is 1 and A is right and after update q_table.loc[S, A] is 0.000000\n",
      "\n",
      "S is 2 episode is 0 step_counter is 26\n",
      "\n",
      "update_env_else\n",
      "--o--T\n",
      " if state_actions is  left     0.0\n",
      "right    0.0\n",
      "Name: 2, dtype: float64  and action_name chosen is  left\n",
      "\n",
      "action chosen is  left\n",
      "After get_env_feedback S_ is 1 and R is 0\n",
      "q_predict is  0.0\n",
      "R is 0 and GAMMA is 0.9 and q_table.iloc[S_, :] is left     0.0\n",
      "right    0.0\n",
      "Name: 1, dtype: float64 and q_target will be 0.0\n",
      "S is 2 and A is left and after update q_table.loc[S, A] is 0.000000\n",
      "\n",
      "S is 1 episode is 0 step_counter is 27\n",
      "\n",
      "update_env_else\n",
      "-o---T\n",
      " if state_actions is  left     0.0\n",
      "right    0.0\n",
      "Name: 1, dtype: float64  and action_name chosen is  left\n",
      "\n",
      "action chosen is  left\n",
      "After get_env_feedback S_ is 0 and R is 0\n",
      "q_predict is  0.0\n",
      "R is 0 and GAMMA is 0.9 and q_table.iloc[S_, :] is left     0.0\n",
      "right    0.0\n",
      "Name: 0, dtype: float64 and q_target will be 0.0\n",
      "S is 1 and A is left and after update q_table.loc[S, A] is 0.000000\n",
      "\n",
      "S is 0 episode is 0 step_counter is 28\n",
      "\n",
      "update_env_else\n",
      "o----T\n",
      " if state_actions is  left     0.0\n",
      "right    0.0\n",
      "Name: 0, dtype: float64  and action_name chosen is  left\n",
      "\n",
      "action chosen is  left\n",
      "After get_env_feedback S_ is 0 and R is 0\n",
      "q_predict is  0.0\n",
      "R is 0 and GAMMA is 0.9 and q_table.iloc[S_, :] is left     0.0\n",
      "right    0.0\n",
      "Name: 0, dtype: float64 and q_target will be 0.0\n",
      "S is 0 and A is left and after update q_table.loc[S, A] is 0.000000\n",
      "\n",
      "S is 0 episode is 0 step_counter is 29\n",
      "\n",
      "update_env_else\n",
      "o----T\n",
      " if state_actions is  left     0.0\n",
      "right    0.0\n",
      "Name: 0, dtype: float64  and action_name chosen is  left\n",
      "\n",
      "action chosen is  left\n",
      "After get_env_feedback S_ is 0 and R is 0\n",
      "q_predict is  0.0\n",
      "R is 0 and GAMMA is 0.9 and q_table.iloc[S_, :] is left     0.0\n",
      "right    0.0\n",
      "Name: 0, dtype: float64 and q_target will be 0.0\n",
      "S is 0 and A is left and after update q_table.loc[S, A] is 0.000000\n",
      "\n",
      "S is 0 episode is 0 step_counter is 30\n",
      "\n",
      "update_env_else\n",
      "o----T\n",
      " if state_actions is  left     0.0\n",
      "right    0.0\n",
      "Name: 0, dtype: float64  and action_name chosen is  left\n",
      "\n",
      "action chosen is  left\n",
      "After get_env_feedback S_ is 0 and R is 0\n",
      "q_predict is  0.0\n",
      "R is 0 and GAMMA is 0.9 and q_table.iloc[S_, :] is left     0.0\n",
      "right    0.0\n",
      "Name: 0, dtype: float64 and q_target will be 0.0\n",
      "S is 0 and A is left and after update q_table.loc[S, A] is 0.000000\n",
      "\n",
      "S is 0 episode is 0 step_counter is 31\n",
      "\n",
      "update_env_else\n",
      "o----T\n",
      " if state_actions is  left     0.0\n",
      "right    0.0\n",
      "Name: 0, dtype: float64  and action_name chosen is  right\n",
      "\n",
      "action chosen is  right\n",
      "After get_env_feedback S_ is 1 and R is 0\n",
      "q_predict is  0.0\n",
      "R is 0 and GAMMA is 0.9 and q_table.iloc[S_, :] is left     0.0\n",
      "right    0.0\n",
      "Name: 1, dtype: float64 and q_target will be 0.0\n",
      "S is 0 and A is right and after update q_table.loc[S, A] is 0.000000\n",
      "\n",
      "S is 1 episode is 0 step_counter is 32\n",
      "\n",
      "update_env_else\n",
      "-o---T\n",
      " if state_actions is  left     0.0\n",
      "right    0.0\n",
      "Name: 1, dtype: float64  and action_name chosen is  left\n",
      "\n",
      "action chosen is  left\n",
      "After get_env_feedback S_ is 0 and R is 0\n",
      "q_predict is  0.0\n",
      "R is 0 and GAMMA is 0.9 and q_table.iloc[S_, :] is left     0.0\n",
      "right    0.0\n",
      "Name: 0, dtype: float64 and q_target will be 0.0\n",
      "S is 1 and A is left and after update q_table.loc[S, A] is 0.000000\n",
      "\n",
      "S is 0 episode is 0 step_counter is 33\n",
      "\n",
      "update_env_else\n",
      "o----T\n",
      " if state_actions is  left     0.0\n",
      "right    0.0\n",
      "Name: 0, dtype: float64  and action_name chosen is  right\n",
      "\n",
      "action chosen is  right\n",
      "After get_env_feedback S_ is 1 and R is 0\n",
      "q_predict is  0.0\n",
      "R is 0 and GAMMA is 0.9 and q_table.iloc[S_, :] is left     0.0\n",
      "right    0.0\n",
      "Name: 1, dtype: float64 and q_target will be 0.0\n",
      "S is 0 and A is right and after update q_table.loc[S, A] is 0.000000\n",
      "\n",
      "S is 1 episode is 0 step_counter is 34\n",
      "\n",
      "update_env_else\n",
      "-o---T\n",
      " if state_actions is  left     0.0\n",
      "right    0.0\n",
      "Name: 1, dtype: float64  and action_name chosen is  right\n",
      "\n",
      "action chosen is  right\n",
      "After get_env_feedback S_ is 2 and R is 0\n",
      "q_predict is  0.0\n",
      "R is 0 and GAMMA is 0.9 and q_table.iloc[S_, :] is left     0.0\n",
      "right    0.0\n",
      "Name: 2, dtype: float64 and q_target will be 0.0\n",
      "S is 1 and A is right and after update q_table.loc[S, A] is 0.000000\n",
      "\n",
      "S is 2 episode is 0 step_counter is 35\n",
      "\n",
      "update_env_else\n",
      "--o--T\n",
      " if state_actions is  left     0.0\n",
      "right    0.0\n",
      "Name: 2, dtype: float64  and action_name chosen is  right\n",
      "\n",
      "action chosen is  right\n",
      "After get_env_feedback S_ is 3 and R is 0\n",
      "q_predict is  0.0\n",
      "R is 0 and GAMMA is 0.9 and q_table.iloc[S_, :] is left     0.0\n",
      "right    0.0\n",
      "Name: 3, dtype: float64 and q_target will be 0.0\n",
      "S is 2 and A is right and after update q_table.loc[S, A] is 0.000000\n",
      "\n",
      "S is 3 episode is 0 step_counter is 36\n",
      "\n",
      "update_env_else\n",
      "---o-T\n",
      " if state_actions is  left     0.0\n",
      "right    0.0\n",
      "Name: 3, dtype: float64  and action_name chosen is  right\n",
      "\n",
      "action chosen is  right\n",
      "After get_env_feedback S_ is 4 and R is 0\n",
      "q_predict is  0.0\n",
      "R is 0 and GAMMA is 0.9 and q_table.iloc[S_, :] is left     0.0\n",
      "right    0.0\n",
      "Name: 4, dtype: float64 and q_target will be 0.0\n",
      "S is 3 and A is right and after update q_table.loc[S, A] is 0.000000\n",
      "\n",
      "S is 4 episode is 0 step_counter is 37\n",
      "\n",
      "update_env_else\n",
      "----oT\n",
      " if state_actions is  left     0.0\n",
      "right    0.0\n",
      "Name: 4, dtype: float64  and action_name chosen is  right\n",
      "\n",
      "action chosen is  right\n",
      "After get_env_feedback S_ is terminal and R is 1\n",
      "q_predict is  0.0\n",
      "S is 4 and A is right and after update q_table.loc[S, A] is 0.000000\n",
      "\n",
      "S is terminal episode is 0 step_counter is 38\n",
      "\n",
      "update_env_if\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1: total_steps = 38\n",
      "update_env_if\n",
      "                                \n",
      "S is 0 episode is 1 step_counter is 0\n",
      "\n",
      "update_env_else\n",
      "o----T\n",
      " if state_actions is  left     0.0\n",
      "right    0.0\n",
      "Name: 0, dtype: float64  and action_name chosen is  left\n",
      "\n",
      "action chosen is  left\n",
      "After get_env_feedback S_ is 0 and R is 0\n",
      "q_predict is  0.0\n",
      "R is 0 and GAMMA is 0.9 and q_table.iloc[S_, :] is left     0.0\n",
      "right    0.0\n",
      "Name: 0, dtype: float64 and q_target will be 0.0\n",
      "S is 0 and A is left and after update q_table.loc[S, A] is 0.000000\n",
      "\n",
      "S is 0 episode is 1 step_counter is 1\n",
      "\n",
      "update_env_else\n",
      "o----T\n",
      " if state_actions is  left     0.0\n",
      "right    0.0\n",
      "Name: 0, dtype: float64  and action_name chosen is  right\n",
      "\n",
      "action chosen is  right\n",
      "After get_env_feedback S_ is 1 and R is 0\n",
      "q_predict is  0.0\n",
      "R is 0 and GAMMA is 0.9 and q_table.iloc[S_, :] is left     0.0\n",
      "right    0.0\n",
      "Name: 1, dtype: float64 and q_target will be 0.0\n",
      "S is 0 and A is right and after update q_table.loc[S, A] is 0.000000\n",
      "\n",
      "S is 1 episode is 1 step_counter is 2\n",
      "\n",
      "update_env_else\n",
      "-o---T\n",
      " if state_actions is  left     0.0\n",
      "right    0.0\n",
      "Name: 1, dtype: float64  and action_name chosen is  left\n",
      "\n",
      "action chosen is  left\n",
      "After get_env_feedback S_ is 0 and R is 0\n",
      "q_predict is  0.0\n",
      "R is 0 and GAMMA is 0.9 and q_table.iloc[S_, :] is left     0.0\n",
      "right    0.0\n",
      "Name: 0, dtype: float64 and q_target will be 0.0\n",
      "S is 1 and A is left and after update q_table.loc[S, A] is 0.000000\n",
      "\n",
      "S is 0 episode is 1 step_counter is 3\n",
      "\n",
      "update_env_else\n",
      "o----T\n",
      " if state_actions is  left     0.0\n",
      "right    0.0\n",
      "Name: 0, dtype: float64  and action_name chosen is  right\n",
      "\n",
      "action chosen is  right\n",
      "After get_env_feedback S_ is 1 and R is 0\n",
      "q_predict is  0.0\n",
      "R is 0 and GAMMA is 0.9 and q_table.iloc[S_, :] is left     0.0\n",
      "right    0.0\n",
      "Name: 1, dtype: float64 and q_target will be 0.0\n",
      "S is 0 and A is right and after update q_table.loc[S, A] is 0.000000\n",
      "\n",
      "S is 1 episode is 1 step_counter is 4\n",
      "\n",
      "update_env_else\n",
      "-o---T\n",
      " if state_actions is  left     0.0\n",
      "right    0.0\n",
      "Name: 1, dtype: float64  and action_name chosen is  left\n",
      "\n",
      "action chosen is  left\n",
      "After get_env_feedback S_ is 0 and R is 0\n",
      "q_predict is  0.0\n",
      "R is 0 and GAMMA is 0.9 and q_table.iloc[S_, :] is left     0.0\n",
      "right    0.0\n",
      "Name: 0, dtype: float64 and q_target will be 0.0\n",
      "S is 1 and A is left and after update q_table.loc[S, A] is 0.000000\n",
      "\n",
      "S is 0 episode is 1 step_counter is 5\n",
      "\n",
      "update_env_else\n",
      "o----T\n",
      " if state_actions is  left     0.0\n",
      "right    0.0\n",
      "Name: 0, dtype: float64  and action_name chosen is  right\n",
      "\n",
      "action chosen is  right\n",
      "After get_env_feedback S_ is 1 and R is 0\n",
      "q_predict is  0.0\n",
      "R is 0 and GAMMA is 0.9 and q_table.iloc[S_, :] is left     0.0\n",
      "right    0.0\n",
      "Name: 1, dtype: float64 and q_target will be 0.0\n",
      "S is 0 and A is right and after update q_table.loc[S, A] is 0.000000\n",
      "\n",
      "S is 1 episode is 1 step_counter is 6\n",
      "\n",
      "update_env_else\n",
      "-o---T\n",
      " if state_actions is  left     0.0\n",
      "right    0.0\n",
      "Name: 1, dtype: float64  and action_name chosen is  right\n",
      "\n",
      "action chosen is  right\n",
      "After get_env_feedback S_ is 2 and R is 0\n",
      "q_predict is  0.0\n",
      "R is 0 and GAMMA is 0.9 and q_table.iloc[S_, :] is left     0.0\n",
      "right    0.0\n",
      "Name: 2, dtype: float64 and q_target will be 0.0\n",
      "S is 1 and A is right and after update q_table.loc[S, A] is 0.000000\n",
      "\n",
      "S is 2 episode is 1 step_counter is 7\n",
      "\n",
      "update_env_else\n",
      "--o--T\n",
      " if state_actions is  left     0.0\n",
      "right    0.0\n",
      "Name: 2, dtype: float64  and action_name chosen is  left\n",
      "\n",
      "action chosen is  left\n",
      "After get_env_feedback S_ is 1 and R is 0\n",
      "q_predict is  0.0\n",
      "R is 0 and GAMMA is 0.9 and q_table.iloc[S_, :] is left     0.0\n",
      "right    0.0\n",
      "Name: 1, dtype: float64 and q_target will be 0.0\n",
      "S is 2 and A is left and after update q_table.loc[S, A] is 0.000000\n",
      "\n",
      "S is 1 episode is 1 step_counter is 8\n",
      "\n",
      "update_env_else\n",
      "-o---T\n",
      " if state_actions is  left     0.0\n",
      "right    0.0\n",
      "Name: 1, dtype: float64  and action_name chosen is  right\n",
      "\n",
      "action chosen is  right\n",
      "After get_env_feedback S_ is 2 and R is 0\n",
      "q_predict is  0.0\n",
      "R is 0 and GAMMA is 0.9 and q_table.iloc[S_, :] is left     0.0\n",
      "right    0.0\n",
      "Name: 2, dtype: float64 and q_target will be 0.0\n",
      "S is 1 and A is right and after update q_table.loc[S, A] is 0.000000\n",
      "\n",
      "S is 2 episode is 1 step_counter is 9\n",
      "\n",
      "update_env_else\n",
      "--o--T\n",
      " if state_actions is  left     0.0\n",
      "right    0.0\n",
      "Name: 2, dtype: float64  and action_name chosen is  left\n",
      "\n",
      "action chosen is  left\n",
      "After get_env_feedback S_ is 1 and R is 0\n",
      "q_predict is  0.0\n",
      "R is 0 and GAMMA is 0.9 and q_table.iloc[S_, :] is left     0.0\n",
      "right    0.0\n",
      "Name: 1, dtype: float64 and q_target will be 0.0\n",
      "S is 2 and A is left and after update q_table.loc[S, A] is 0.000000\n",
      "\n",
      "S is 1 episode is 1 step_counter is 10\n",
      "\n",
      "update_env_else\n",
      "-o---T\n",
      " if state_actions is  left     0.0\n",
      "right    0.0\n",
      "Name: 1, dtype: float64  and action_name chosen is  right\n",
      "\n",
      "action chosen is  right\n",
      "After get_env_feedback S_ is 2 and R is 0\n",
      "q_predict is  0.0\n",
      "R is 0 and GAMMA is 0.9 and q_table.iloc[S_, :] is left     0.0\n",
      "right    0.0\n",
      "Name: 2, dtype: float64 and q_target will be 0.0\n",
      "S is 1 and A is right and after update q_table.loc[S, A] is 0.000000\n",
      "\n",
      "S is 2 episode is 1 step_counter is 11\n",
      "\n",
      "update_env_else\n",
      "--o--T\n",
      " if state_actions is  left     0.0\n",
      "right    0.0\n",
      "Name: 2, dtype: float64  and action_name chosen is  right\n",
      "\n",
      "action chosen is  right\n",
      "After get_env_feedback S_ is 3 and R is 0\n",
      "q_predict is  0.0\n",
      "R is 0 and GAMMA is 0.9 and q_table.iloc[S_, :] is left     0.0\n",
      "right    0.0\n",
      "Name: 3, dtype: float64 and q_target will be 0.0\n",
      "S is 2 and A is right and after update q_table.loc[S, A] is 0.000000\n",
      "\n",
      "S is 3 episode is 1 step_counter is 12\n",
      "\n",
      "update_env_else\n",
      "---o-T\n",
      " if state_actions is  left     0.0\n",
      "right    0.0\n",
      "Name: 3, dtype: float64  and action_name chosen is  left\n",
      "\n",
      "action chosen is  left\n",
      "After get_env_feedback S_ is 2 and R is 0\n",
      "q_predict is  0.0\n",
      "R is 0 and GAMMA is 0.9 and q_table.iloc[S_, :] is left     0.0\n",
      "right    0.0\n",
      "Name: 2, dtype: float64 and q_target will be 0.0\n",
      "S is 3 and A is left and after update q_table.loc[S, A] is 0.000000\n",
      "\n",
      "S is 2 episode is 1 step_counter is 13\n",
      "\n",
      "update_env_else\n",
      "--o--T\n",
      " if state_actions is  left     0.0\n",
      "right    0.0\n",
      "Name: 2, dtype: float64  and action_name chosen is  left\n",
      "\n",
      "action chosen is  left\n",
      "After get_env_feedback S_ is 1 and R is 0\n",
      "q_predict is  0.0\n",
      "R is 0 and GAMMA is 0.9 and q_table.iloc[S_, :] is left     0.0\n",
      "right    0.0\n",
      "Name: 1, dtype: float64 and q_target will be 0.0\n",
      "S is 2 and A is left and after update q_table.loc[S, A] is 0.000000\n",
      "\n",
      "S is 1 episode is 1 step_counter is 14\n",
      "\n",
      "update_env_else\n",
      "-o---T\n",
      " if state_actions is  left     0.0\n",
      "right    0.0\n",
      "Name: 1, dtype: float64  and action_name chosen is  right\n",
      "\n",
      "action chosen is  right\n",
      "After get_env_feedback S_ is 2 and R is 0\n",
      "q_predict is  0.0\n",
      "R is 0 and GAMMA is 0.9 and q_table.iloc[S_, :] is left     0.0\n",
      "right    0.0\n",
      "Name: 2, dtype: float64 and q_target will be 0.0\n",
      "S is 1 and A is right and after update q_table.loc[S, A] is 0.000000\n",
      "\n",
      "S is 2 episode is 1 step_counter is 15\n",
      "\n",
      "update_env_else\n",
      "--o--T\n",
      " if state_actions is  left     0.0\n",
      "right    0.0\n",
      "Name: 2, dtype: float64  and action_name chosen is  left\n",
      "\n",
      "action chosen is  left\n",
      "After get_env_feedback S_ is 1 and R is 0\n",
      "q_predict is  0.0\n",
      "R is 0 and GAMMA is 0.9 and q_table.iloc[S_, :] is left     0.0\n",
      "right    0.0\n",
      "Name: 1, dtype: float64 and q_target will be 0.0\n",
      "S is 2 and A is left and after update q_table.loc[S, A] is 0.000000\n",
      "\n",
      "S is 1 episode is 1 step_counter is 16\n",
      "\n",
      "update_env_else\n",
      "-o---T\n",
      " if state_actions is  left     0.0\n",
      "right    0.0\n",
      "Name: 1, dtype: float64  and action_name chosen is  left\n",
      "\n",
      "action chosen is  left\n",
      "After get_env_feedback S_ is 0 and R is 0\n",
      "q_predict is  0.0\n",
      "R is 0 and GAMMA is 0.9 and q_table.iloc[S_, :] is left     0.0\n",
      "right    0.0\n",
      "Name: 0, dtype: float64 and q_target will be 0.0\n",
      "S is 1 and A is left and after update q_table.loc[S, A] is 0.000000\n",
      "\n",
      "S is 0 episode is 1 step_counter is 17\n",
      "\n",
      "update_env_else\n",
      "o----T\n",
      " if state_actions is  left     0.0\n",
      "right    0.0\n",
      "Name: 0, dtype: float64  and action_name chosen is  right\n",
      "\n",
      "action chosen is  right\n",
      "After get_env_feedback S_ is 1 and R is 0\n",
      "q_predict is  0.0\n",
      "R is 0 and GAMMA is 0.9 and q_table.iloc[S_, :] is left     0.0\n",
      "right    0.0\n",
      "Name: 1, dtype: float64 and q_target will be 0.0\n",
      "S is 0 and A is right and after update q_table.loc[S, A] is 0.000000\n",
      "\n",
      "S is 1 episode is 1 step_counter is 18\n",
      "\n",
      "update_env_else\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-o---T\n",
      " if state_actions is  left     0.0\n",
      "right    0.0\n",
      "Name: 1, dtype: float64  and action_name chosen is  right\n",
      "\n",
      "action chosen is  right\n",
      "After get_env_feedback S_ is 2 and R is 0\n",
      "q_predict is  0.0\n",
      "R is 0 and GAMMA is 0.9 and q_table.iloc[S_, :] is left     0.0\n",
      "right    0.0\n",
      "Name: 2, dtype: float64 and q_target will be 0.0\n",
      "S is 1 and A is right and after update q_table.loc[S, A] is 0.000000\n",
      "\n",
      "S is 2 episode is 1 step_counter is 19\n",
      "\n",
      "update_env_else\n",
      "--o--T\n",
      " if state_actions is  left     0.0\n",
      "right    0.0\n",
      "Name: 2, dtype: float64  and action_name chosen is  right\n",
      "\n",
      "action chosen is  right\n",
      "After get_env_feedback S_ is 3 and R is 0\n",
      "q_predict is  0.0\n",
      "R is 0 and GAMMA is 0.9 and q_table.iloc[S_, :] is left     0.0\n",
      "right    0.0\n",
      "Name: 3, dtype: float64 and q_target will be 0.0\n",
      "S is 2 and A is right and after update q_table.loc[S, A] is 0.000000\n",
      "\n",
      "S is 3 episode is 1 step_counter is 20\n",
      "\n",
      "update_env_else\n",
      "---o-T\n",
      " if state_actions is  left     0.0\n",
      "right    0.0\n",
      "Name: 3, dtype: float64  and action_name chosen is  right\n",
      "\n",
      "action chosen is  right\n",
      "After get_env_feedback S_ is 4 and R is 0\n",
      "q_predict is  0.0\n",
      "R is 0 and GAMMA is 0.9 and q_table.iloc[S_, :] is left     0.0\n",
      "right    0.0\n",
      "Name: 4, dtype: float64 and q_target will be 0.0\n",
      "S is 3 and A is right and after update q_table.loc[S, A] is 0.000000\n",
      "\n",
      "S is 4 episode is 1 step_counter is 21\n",
      "\n",
      "update_env_else\n",
      "----oT\n",
      " if state_actions is  left     0.0\n",
      "right    0.0\n",
      "Name: 4, dtype: float64  and action_name chosen is  left\n",
      "\n",
      "action chosen is  left\n",
      "After get_env_feedback S_ is 3 and R is 0\n",
      "q_predict is  0.0\n",
      "R is 0 and GAMMA is 0.9 and q_table.iloc[S_, :] is left     0.0\n",
      "right    0.0\n",
      "Name: 3, dtype: float64 and q_target will be 0.0\n",
      "S is 4 and A is left and after update q_table.loc[S, A] is 0.000000\n",
      "\n",
      "S is 3 episode is 1 step_counter is 22\n",
      "\n",
      "update_env_else\n",
      "---o-T\n",
      " if state_actions is  left     0.0\n",
      "right    0.0\n",
      "Name: 3, dtype: float64  and action_name chosen is  left\n",
      "\n",
      "action chosen is  left\n",
      "After get_env_feedback S_ is 2 and R is 0\n",
      "q_predict is  0.0\n",
      "R is 0 and GAMMA is 0.9 and q_table.iloc[S_, :] is left     0.0\n",
      "right    0.0\n",
      "Name: 2, dtype: float64 and q_target will be 0.0\n",
      "S is 3 and A is left and after update q_table.loc[S, A] is 0.000000\n",
      "\n",
      "S is 2 episode is 1 step_counter is 23\n",
      "\n",
      "update_env_else\n",
      "--o--T\n",
      " if state_actions is  left     0.0\n",
      "right    0.0\n",
      "Name: 2, dtype: float64  and action_name chosen is  right\n",
      "\n",
      "action chosen is  right\n",
      "After get_env_feedback S_ is 3 and R is 0\n",
      "q_predict is  0.0\n",
      "R is 0 and GAMMA is 0.9 and q_table.iloc[S_, :] is left     0.0\n",
      "right    0.0\n",
      "Name: 3, dtype: float64 and q_target will be 0.0\n",
      "S is 2 and A is right and after update q_table.loc[S, A] is 0.000000\n",
      "\n",
      "S is 3 episode is 1 step_counter is 24\n",
      "\n",
      "update_env_else\n",
      "---o-T\n",
      " if state_actions is  left     0.0\n",
      "right    0.0\n",
      "Name: 3, dtype: float64  and action_name chosen is  left\n",
      "\n",
      "action chosen is  left\n",
      "After get_env_feedback S_ is 2 and R is 0\n",
      "q_predict is  0.0\n",
      "R is 0 and GAMMA is 0.9 and q_table.iloc[S_, :] is left     0.0\n",
      "right    0.0\n",
      "Name: 2, dtype: float64 and q_target will be 0.0\n",
      "S is 3 and A is left and after update q_table.loc[S, A] is 0.000000\n",
      "\n",
      "S is 2 episode is 1 step_counter is 25\n",
      "\n",
      "update_env_else\n",
      "--o--T\n",
      " if state_actions is  left     0.0\n",
      "right    0.0\n",
      "Name: 2, dtype: float64  and action_name chosen is  right\n",
      "\n",
      "action chosen is  right\n",
      "After get_env_feedback S_ is 3 and R is 0\n",
      "q_predict is  0.0\n",
      "R is 0 and GAMMA is 0.9 and q_table.iloc[S_, :] is left     0.0\n",
      "right    0.0\n",
      "Name: 3, dtype: float64 and q_target will be 0.0\n",
      "S is 2 and A is right and after update q_table.loc[S, A] is 0.000000\n",
      "\n",
      "S is 3 episode is 1 step_counter is 26\n",
      "\n",
      "update_env_else\n",
      "---o-T\n",
      " if state_actions is  left     0.0\n",
      "right    0.0\n",
      "Name: 3, dtype: float64  and action_name chosen is  left\n",
      "\n",
      "action chosen is  left\n",
      "After get_env_feedback S_ is 2 and R is 0\n",
      "q_predict is  0.0\n",
      "R is 0 and GAMMA is 0.9 and q_table.iloc[S_, :] is left     0.0\n",
      "right    0.0\n",
      "Name: 2, dtype: float64 and q_target will be 0.0\n",
      "S is 3 and A is left and after update q_table.loc[S, A] is 0.000000\n",
      "\n",
      "S is 2 episode is 1 step_counter is 27\n",
      "\n",
      "update_env_else\n",
      "--o--T\n",
      " if state_actions is  left     0.0\n",
      "right    0.0\n",
      "Name: 2, dtype: float64  and action_name chosen is  left\n",
      "\n",
      "action chosen is  left\n",
      "After get_env_feedback S_ is 1 and R is 0\n",
      "q_predict is  0.0\n",
      "R is 0 and GAMMA is 0.9 and q_table.iloc[S_, :] is left     0.0\n",
      "right    0.0\n",
      "Name: 1, dtype: float64 and q_target will be 0.0\n",
      "S is 2 and A is left and after update q_table.loc[S, A] is 0.000000\n",
      "\n",
      "S is 1 episode is 1 step_counter is 28\n",
      "\n",
      "update_env_else\n",
      "-o---T\n",
      " if state_actions is  left     0.0\n",
      "right    0.0\n",
      "Name: 1, dtype: float64  and action_name chosen is  left\n",
      "\n",
      "action chosen is  left\n",
      "After get_env_feedback S_ is 0 and R is 0\n",
      "q_predict is  0.0\n",
      "R is 0 and GAMMA is 0.9 and q_table.iloc[S_, :] is left     0.0\n",
      "right    0.0\n",
      "Name: 0, dtype: float64 and q_target will be 0.0\n",
      "S is 1 and A is left and after update q_table.loc[S, A] is 0.000000\n",
      "\n",
      "S is 0 episode is 1 step_counter is 29\n",
      "\n",
      "update_env_else\n",
      "o----T\n",
      " if state_actions is  left     0.0\n",
      "right    0.0\n",
      "Name: 0, dtype: float64  and action_name chosen is  right\n",
      "\n",
      "action chosen is  right\n",
      "After get_env_feedback S_ is 1 and R is 0\n",
      "q_predict is  0.0\n",
      "R is 0 and GAMMA is 0.9 and q_table.iloc[S_, :] is left     0.0\n",
      "right    0.0\n",
      "Name: 1, dtype: float64 and q_target will be 0.0\n",
      "S is 0 and A is right and after update q_table.loc[S, A] is 0.000000\n",
      "\n",
      "S is 1 episode is 1 step_counter is 30\n",
      "\n",
      "update_env_else\n",
      "-o---T\n",
      " if state_actions is  left     0.0\n",
      "right    0.0\n",
      "Name: 1, dtype: float64  and action_name chosen is  right\n",
      "\n",
      "action chosen is  right\n",
      "After get_env_feedback S_ is 2 and R is 0\n",
      "q_predict is  0.0\n",
      "R is 0 and GAMMA is 0.9 and q_table.iloc[S_, :] is left     0.0\n",
      "right    0.0\n",
      "Name: 2, dtype: float64 and q_target will be 0.0\n",
      "S is 1 and A is right and after update q_table.loc[S, A] is 0.000000\n",
      "\n",
      "S is 2 episode is 1 step_counter is 31\n",
      "\n",
      "update_env_else\n",
      "--o--T\n",
      " if state_actions is  left     0.0\n",
      "right    0.0\n",
      "Name: 2, dtype: float64  and action_name chosen is  right\n",
      "\n",
      "action chosen is  right\n",
      "After get_env_feedback S_ is 3 and R is 0\n",
      "q_predict is  0.0\n",
      "R is 0 and GAMMA is 0.9 and q_table.iloc[S_, :] is left     0.0\n",
      "right    0.0\n",
      "Name: 3, dtype: float64 and q_target will be 0.0\n",
      "S is 2 and A is right and after update q_table.loc[S, A] is 0.000000\n",
      "\n",
      "S is 3 episode is 1 step_counter is 32\n",
      "\n",
      "update_env_else\n",
      "---o-T\n",
      " if state_actions is  left     0.0\n",
      "right    0.0\n",
      "Name: 3, dtype: float64  and action_name chosen is  right\n",
      "\n",
      "action chosen is  right\n",
      "After get_env_feedback S_ is 4 and R is 0\n",
      "q_predict is  0.0\n",
      "R is 0 and GAMMA is 0.9 and q_table.iloc[S_, :] is left     0.0\n",
      "right    0.0\n",
      "Name: 4, dtype: float64 and q_target will be 0.0\n",
      "S is 3 and A is right and after update q_table.loc[S, A] is 0.000000\n",
      "\n",
      "S is 4 episode is 1 step_counter is 33\n",
      "\n",
      "update_env_else\n",
      "----oT\n",
      " if state_actions is  left     0.0\n",
      "right    0.0\n",
      "Name: 4, dtype: float64  and action_name chosen is  right\n",
      "\n",
      "action chosen is  right\n",
      "After get_env_feedback S_ is terminal and R is 1\n",
      "q_predict is  0.0\n",
      "S is 4 and A is right and after update q_table.loc[S, A] is 0.000000\n",
      "\n",
      "S is terminal episode is 1 step_counter is 34\n",
      "\n",
      "update_env_if\n",
      "Episode 2: total_steps = 34\n",
      "update_env_if\n",
      "                                \n",
      "S is 0 episode is 2 step_counter is 0\n",
      "\n",
      "update_env_else\n",
      "o----T\n",
      " if state_actions is  left     0.0\n",
      "right    0.0\n",
      "Name: 0, dtype: float64  and action_name chosen is  right\n",
      "\n",
      "action chosen is  right\n",
      "After get_env_feedback S_ is 1 and R is 0\n",
      "q_predict is  0.0\n",
      "R is 0 and GAMMA is 0.9 and q_table.iloc[S_, :] is left     0.0\n",
      "right    0.0\n",
      "Name: 1, dtype: float64 and q_target will be 0.0\n",
      "S is 0 and A is right and after update q_table.loc[S, A] is 0.000000\n",
      "\n",
      "S is 1 episode is 2 step_counter is 1\n",
      "\n",
      "update_env_else\n",
      "-o---T\n",
      " if state_actions is  left     0.0\n",
      "right    0.0\n",
      "Name: 1, dtype: float64  and action_name chosen is  right\n",
      "\n",
      "action chosen is  right\n",
      "After get_env_feedback S_ is 2 and R is 0\n",
      "q_predict is  0.0\n",
      "R is 0 and GAMMA is 0.9 and q_table.iloc[S_, :] is left     0.0\n",
      "right    0.0\n",
      "Name: 2, dtype: float64 and q_target will be 0.0\n",
      "S is 1 and A is right and after update q_table.loc[S, A] is 0.000000\n",
      "\n",
      "S is 2 episode is 2 step_counter is 2\n",
      "\n",
      "update_env_else\n",
      "--o--T\n",
      " if state_actions is  left     0.0\n",
      "right    0.0\n",
      "Name: 2, dtype: float64  and action_name chosen is  left\n",
      "\n",
      "action chosen is  left\n",
      "After get_env_feedback S_ is 1 and R is 0\n",
      "q_predict is  0.0\n",
      "R is 0 and GAMMA is 0.9 and q_table.iloc[S_, :] is left     0.0\n",
      "right    0.0\n",
      "Name: 1, dtype: float64 and q_target will be 0.0\n",
      "S is 2 and A is left and after update q_table.loc[S, A] is 0.000000\n",
      "\n",
      "S is 1 episode is 2 step_counter is 3\n",
      "\n",
      "update_env_else\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-o---T\n",
      " if state_actions is  left     0.0\n",
      "right    0.0\n",
      "Name: 1, dtype: float64  and action_name chosen is  right\n",
      "\n",
      "action chosen is  right\n",
      "After get_env_feedback S_ is 2 and R is 0\n",
      "q_predict is  0.0\n",
      "R is 0 and GAMMA is 0.9 and q_table.iloc[S_, :] is left     0.0\n",
      "right    0.0\n",
      "Name: 2, dtype: float64 and q_target will be 0.0\n",
      "S is 1 and A is right and after update q_table.loc[S, A] is 0.000000\n",
      "\n",
      "S is 2 episode is 2 step_counter is 4\n",
      "\n",
      "update_env_else\n",
      "--o--T\n",
      " if state_actions is  left     0.0\n",
      "right    0.0\n",
      "Name: 2, dtype: float64  and action_name chosen is  left\n",
      "\n",
      "action chosen is  left\n",
      "After get_env_feedback S_ is 1 and R is 0\n",
      "q_predict is  0.0\n",
      "R is 0 and GAMMA is 0.9 and q_table.iloc[S_, :] is left     0.0\n",
      "right    0.0\n",
      "Name: 1, dtype: float64 and q_target will be 0.0\n",
      "S is 2 and A is left and after update q_table.loc[S, A] is 0.000000\n",
      "\n",
      "S is 1 episode is 2 step_counter is 5\n",
      "\n",
      "update_env_else\n",
      "-o---T\n",
      " if state_actions is  left     0.0\n",
      "right    0.0\n",
      "Name: 1, dtype: float64  and action_name chosen is  left\n",
      "\n",
      "action chosen is  left\n",
      "After get_env_feedback S_ is 0 and R is 0\n",
      "q_predict is  0.0\n",
      "R is 0 and GAMMA is 0.9 and q_table.iloc[S_, :] is left     0.0\n",
      "right    0.0\n",
      "Name: 0, dtype: float64 and q_target will be 0.0\n",
      "S is 1 and A is left and after update q_table.loc[S, A] is 0.000000\n",
      "\n",
      "S is 0 episode is 2 step_counter is 6\n",
      "\n",
      "update_env_else\n",
      "o----T\n",
      " if state_actions is  left     0.0\n",
      "right    0.0\n",
      "Name: 0, dtype: float64  and action_name chosen is  right\n",
      "\n",
      "action chosen is  right\n",
      "After get_env_feedback S_ is 1 and R is 0\n",
      "q_predict is  0.0\n",
      "R is 0 and GAMMA is 0.9 and q_table.iloc[S_, :] is left     0.0\n",
      "right    0.0\n",
      "Name: 1, dtype: float64 and q_target will be 0.0\n",
      "S is 0 and A is right and after update q_table.loc[S, A] is 0.000000\n",
      "\n",
      "S is 1 episode is 2 step_counter is 7\n",
      "\n",
      "update_env_else\n",
      "-o---T\n",
      " if state_actions is  left     0.0\n",
      "right    0.0\n",
      "Name: 1, dtype: float64  and action_name chosen is  left\n",
      "\n",
      "action chosen is  left\n",
      "After get_env_feedback S_ is 0 and R is 0\n",
      "q_predict is  0.0\n",
      "R is 0 and GAMMA is 0.9 and q_table.iloc[S_, :] is left     0.0\n",
      "right    0.0\n",
      "Name: 0, dtype: float64 and q_target will be 0.0\n",
      "S is 1 and A is left and after update q_table.loc[S, A] is 0.000000\n",
      "\n",
      "S is 0 episode is 2 step_counter is 8\n",
      "\n",
      "update_env_else\n",
      "o----T\n",
      " if state_actions is  left     0.0\n",
      "right    0.0\n",
      "Name: 0, dtype: float64  and action_name chosen is  right\n",
      "\n",
      "action chosen is  right\n",
      "After get_env_feedback S_ is 1 and R is 0\n",
      "q_predict is  0.0\n",
      "R is 0 and GAMMA is 0.9 and q_table.iloc[S_, :] is left     0.0\n",
      "right    0.0\n",
      "Name: 1, dtype: float64 and q_target will be 0.0\n",
      "S is 0 and A is right and after update q_table.loc[S, A] is 0.000000\n",
      "\n",
      "S is 1 episode is 2 step_counter is 9\n",
      "\n",
      "update_env_else\n",
      "-o---T\n",
      " if state_actions is  left     0.0\n",
      "right    0.0\n",
      "Name: 1, dtype: float64  and action_name chosen is  right\n",
      "\n",
      "action chosen is  right\n",
      "After get_env_feedback S_ is 2 and R is 0\n",
      "q_predict is  0.0\n",
      "R is 0 and GAMMA is 0.9 and q_table.iloc[S_, :] is left     0.0\n",
      "right    0.0\n",
      "Name: 2, dtype: float64 and q_target will be 0.0\n",
      "S is 1 and A is right and after update q_table.loc[S, A] is 0.000000\n",
      "\n",
      "S is 2 episode is 2 step_counter is 10\n",
      "\n",
      "update_env_else\n",
      "--o--T\n",
      " if state_actions is  left     0.0\n",
      "right    0.0\n",
      "Name: 2, dtype: float64  and action_name chosen is  right\n",
      "\n",
      "action chosen is  right\n",
      "After get_env_feedback S_ is 3 and R is 0\n",
      "q_predict is  0.0\n",
      "R is 0 and GAMMA is 0.9 and q_table.iloc[S_, :] is left     0.0\n",
      "right    0.0\n",
      "Name: 3, dtype: float64 and q_target will be 0.0\n",
      "S is 2 and A is right and after update q_table.loc[S, A] is 0.000000\n",
      "\n",
      "S is 3 episode is 2 step_counter is 11\n",
      "\n",
      "update_env_else\n",
      "---o-T\n",
      " if state_actions is  left     0.0\n",
      "right    0.0\n",
      "Name: 3, dtype: float64  and action_name chosen is  left\n",
      "\n",
      "action chosen is  left\n",
      "After get_env_feedback S_ is 2 and R is 0\n",
      "q_predict is  0.0\n",
      "R is 0 and GAMMA is 0.9 and q_table.iloc[S_, :] is left     0.0\n",
      "right    0.0\n",
      "Name: 2, dtype: float64 and q_target will be 0.0\n",
      "S is 3 and A is left and after update q_table.loc[S, A] is 0.000000\n",
      "\n",
      "S is 2 episode is 2 step_counter is 12\n",
      "\n",
      "update_env_else\n",
      "--o--T\n",
      " if state_actions is  left     0.0\n",
      "right    0.0\n",
      "Name: 2, dtype: float64  and action_name chosen is  right\n",
      "\n",
      "action chosen is  right\n",
      "After get_env_feedback S_ is 3 and R is 0\n",
      "q_predict is  0.0\n",
      "R is 0 and GAMMA is 0.9 and q_table.iloc[S_, :] is left     0.0\n",
      "right    0.0\n",
      "Name: 3, dtype: float64 and q_target will be 0.0\n",
      "S is 2 and A is right and after update q_table.loc[S, A] is 0.000000\n",
      "\n",
      "S is 3 episode is 2 step_counter is 13\n",
      "\n",
      "update_env_else\n",
      "---o-T\n",
      " if state_actions is  left     0.0\n",
      "right    0.0\n",
      "Name: 3, dtype: float64  and action_name chosen is  left\n",
      "\n",
      "action chosen is  left\n",
      "After get_env_feedback S_ is 2 and R is 0\n",
      "q_predict is  0.0\n",
      "R is 0 and GAMMA is 0.9 and q_table.iloc[S_, :] is left     0.0\n",
      "right    0.0\n",
      "Name: 2, dtype: float64 and q_target will be 0.0\n",
      "S is 3 and A is left and after update q_table.loc[S, A] is 0.000000\n",
      "\n",
      "S is 2 episode is 2 step_counter is 14\n",
      "\n",
      "update_env_else\n",
      "--o--T\n",
      " if state_actions is  left     0.0\n",
      "right    0.0\n",
      "Name: 2, dtype: float64  and action_name chosen is  right\n",
      "\n",
      "action chosen is  right\n",
      "After get_env_feedback S_ is 3 and R is 0\n",
      "q_predict is  0.0\n",
      "R is 0 and GAMMA is 0.9 and q_table.iloc[S_, :] is left     0.0\n",
      "right    0.0\n",
      "Name: 3, dtype: float64 and q_target will be 0.0\n",
      "S is 2 and A is right and after update q_table.loc[S, A] is 0.000000\n",
      "\n",
      "S is 3 episode is 2 step_counter is 15\n",
      "\n",
      "update_env_else\n",
      "---o-T\n",
      " if state_actions is  left     0.0\n",
      "right    0.0\n",
      "Name: 3, dtype: float64  and action_name chosen is  right\n",
      "\n",
      "action chosen is  right\n",
      "After get_env_feedback S_ is 4 and R is 0\n",
      "q_predict is  0.0\n",
      "R is 0 and GAMMA is 0.9 and q_table.iloc[S_, :] is left     0.0\n",
      "right    0.0\n",
      "Name: 4, dtype: float64 and q_target will be 0.0\n",
      "S is 3 and A is right and after update q_table.loc[S, A] is 0.000000\n",
      "\n",
      "S is 4 episode is 2 step_counter is 16\n",
      "\n",
      "update_env_else\n",
      "----oT\n",
      " if state_actions is  left     0.0\n",
      "right    0.0\n",
      "Name: 4, dtype: float64  and action_name chosen is  left\n",
      "\n",
      "action chosen is  left\n",
      "After get_env_feedback S_ is 3 and R is 0\n",
      "q_predict is  0.0\n",
      "R is 0 and GAMMA is 0.9 and q_table.iloc[S_, :] is left     0.0\n",
      "right    0.0\n",
      "Name: 3, dtype: float64 and q_target will be 0.0\n",
      "S is 4 and A is left and after update q_table.loc[S, A] is 0.000000\n",
      "\n",
      "S is 3 episode is 2 step_counter is 17\n",
      "\n",
      "update_env_else\n",
      "---o-T\n",
      " if state_actions is  left     0.0\n",
      "right    0.0\n",
      "Name: 3, dtype: float64  and action_name chosen is  right\n",
      "\n",
      "action chosen is  right\n",
      "After get_env_feedback S_ is 4 and R is 0\n",
      "q_predict is  0.0\n",
      "R is 0 and GAMMA is 0.9 and q_table.iloc[S_, :] is left     0.0\n",
      "right    0.0\n",
      "Name: 4, dtype: float64 and q_target will be 0.0\n",
      "S is 3 and A is right and after update q_table.loc[S, A] is 0.000000\n",
      "\n",
      "S is 4 episode is 2 step_counter is 18\n",
      "\n",
      "update_env_else\n",
      "----oT\n",
      " if state_actions is  left     0.0\n",
      "right    0.0\n",
      "Name: 4, dtype: float64  and action_name chosen is  right\n",
      "\n",
      "action chosen is  right\n",
      "After get_env_feedback S_ is terminal and R is 1\n",
      "q_predict is  0.0\n",
      "S is 4 and A is right and after update q_table.loc[S, A] is 0.000000\n",
      "\n",
      "S is terminal episode is 2 step_counter is 19\n",
      "\n",
      "update_env_if\n",
      "Episode 3: total_steps = 19\n",
      "update_env_if\n",
      "                                \n",
      "S is 0 episode is 3 step_counter is 0\n",
      "\n",
      "update_env_else\n",
      "o----T\n",
      " if state_actions is  left     0.0\n",
      "right    0.0\n",
      "Name: 0, dtype: float64  and action_name chosen is  left\n",
      "\n",
      "action chosen is  left\n",
      "After get_env_feedback S_ is 0 and R is 0\n",
      "q_predict is  0.0\n",
      "R is 0 and GAMMA is 0.9 and q_table.iloc[S_, :] is left     0.0\n",
      "right    0.0\n",
      "Name: 0, dtype: float64 and q_target will be 0.0\n",
      "S is 0 and A is left and after update q_table.loc[S, A] is 0.000000\n",
      "\n",
      "S is 0 episode is 3 step_counter is 1\n",
      "\n",
      "update_env_else\n",
      "o----T\n",
      " if state_actions is  left     0.0\n",
      "right    0.0\n",
      "Name: 0, dtype: float64  and action_name chosen is  right\n",
      "\n",
      "action chosen is  right\n",
      "After get_env_feedback S_ is 1 and R is 0\n",
      "q_predict is  0.0\n",
      "R is 0 and GAMMA is 0.9 and q_table.iloc[S_, :] is left     0.0\n",
      "right    0.0\n",
      "Name: 1, dtype: float64 and q_target will be 0.0\n",
      "S is 0 and A is right and after update q_table.loc[S, A] is 0.000000\n",
      "\n",
      "S is 1 episode is 3 step_counter is 2\n",
      "\n",
      "update_env_else\n",
      "-o---T\n",
      " if state_actions is  left     0.0\n",
      "right    0.0\n",
      "Name: 1, dtype: float64  and action_name chosen is  left\n",
      "\n",
      "action chosen is  left\n",
      "After get_env_feedback S_ is 0 and R is 0\n",
      "q_predict is  0.0\n",
      "R is 0 and GAMMA is 0.9 and q_table.iloc[S_, :] is left     0.0\n",
      "right    0.0\n",
      "Name: 0, dtype: float64 and q_target will be 0.0\n",
      "S is 1 and A is left and after update q_table.loc[S, A] is 0.000000\n",
      "\n",
      "S is 0 episode is 3 step_counter is 3\n",
      "\n",
      "update_env_else\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "o----T\n",
      " if state_actions is  left     0.0\n",
      "right    0.0\n",
      "Name: 0, dtype: float64  and action_name chosen is  left\n",
      "\n",
      "action chosen is  left\n",
      "After get_env_feedback S_ is 0 and R is 0\n",
      "q_predict is  0.0\n",
      "R is 0 and GAMMA is 0.9 and q_table.iloc[S_, :] is left     0.0\n",
      "right    0.0\n",
      "Name: 0, dtype: float64 and q_target will be 0.0\n",
      "S is 0 and A is left and after update q_table.loc[S, A] is 0.000000\n",
      "\n",
      "S is 0 episode is 3 step_counter is 4\n",
      "\n",
      "update_env_else\n",
      "o----T\n",
      " if state_actions is  left     0.0\n",
      "right    0.0\n",
      "Name: 0, dtype: float64  and action_name chosen is  right\n",
      "\n",
      "action chosen is  right\n",
      "After get_env_feedback S_ is 1 and R is 0\n",
      "q_predict is  0.0\n",
      "R is 0 and GAMMA is 0.9 and q_table.iloc[S_, :] is left     0.0\n",
      "right    0.0\n",
      "Name: 1, dtype: float64 and q_target will be 0.0\n",
      "S is 0 and A is right and after update q_table.loc[S, A] is 0.000000\n",
      "\n",
      "S is 1 episode is 3 step_counter is 5\n",
      "\n",
      "update_env_else\n",
      "-o---T\n",
      " if state_actions is  left     0.0\n",
      "right    0.0\n",
      "Name: 1, dtype: float64  and action_name chosen is  left\n",
      "\n",
      "action chosen is  left\n",
      "After get_env_feedback S_ is 0 and R is 0\n",
      "q_predict is  0.0\n",
      "R is 0 and GAMMA is 0.9 and q_table.iloc[S_, :] is left     0.0\n",
      "right    0.0\n",
      "Name: 0, dtype: float64 and q_target will be 0.0\n",
      "S is 1 and A is left and after update q_table.loc[S, A] is 0.000000\n",
      "\n",
      "S is 0 episode is 3 step_counter is 6\n",
      "\n",
      "update_env_else\n",
      "o----T\n",
      " if state_actions is  left     0.0\n",
      "right    0.0\n",
      "Name: 0, dtype: float64  and action_name chosen is  left\n",
      "\n",
      "action chosen is  left\n",
      "After get_env_feedback S_ is 0 and R is 0\n",
      "q_predict is  0.0\n",
      "R is 0 and GAMMA is 0.9 and q_table.iloc[S_, :] is left     0.0\n",
      "right    0.0\n",
      "Name: 0, dtype: float64 and q_target will be 0.0\n",
      "S is 0 and A is left and after update q_table.loc[S, A] is 0.000000\n",
      "\n",
      "S is 0 episode is 3 step_counter is 7\n",
      "\n",
      "update_env_else\n",
      "o----T\n",
      " if state_actions is  left     0.0\n",
      "right    0.0\n",
      "Name: 0, dtype: float64  and action_name chosen is  left\n",
      "\n",
      "action chosen is  left\n",
      "After get_env_feedback S_ is 0 and R is 0\n",
      "q_predict is  0.0\n",
      "R is 0 and GAMMA is 0.9 and q_table.iloc[S_, :] is left     0.0\n",
      "right    0.0\n",
      "Name: 0, dtype: float64 and q_target will be 0.0\n",
      "S is 0 and A is left and after update q_table.loc[S, A] is 0.000000\n",
      "\n",
      "S is 0 episode is 3 step_counter is 8\n",
      "\n",
      "update_env_else\n",
      "o----T\n",
      " if state_actions is  left     0.0\n",
      "right    0.0\n",
      "Name: 0, dtype: float64  and action_name chosen is  right\n",
      "\n",
      "action chosen is  right\n",
      "After get_env_feedback S_ is 1 and R is 0\n",
      "q_predict is  0.0\n",
      "R is 0 and GAMMA is 0.9 and q_table.iloc[S_, :] is left     0.0\n",
      "right    0.0\n",
      "Name: 1, dtype: float64 and q_target will be 0.0\n",
      "S is 0 and A is right and after update q_table.loc[S, A] is 0.000000\n",
      "\n",
      "S is 1 episode is 3 step_counter is 9\n",
      "\n",
      "update_env_else\n",
      "-o---T\n",
      " if state_actions is  left     0.0\n",
      "right    0.0\n",
      "Name: 1, dtype: float64  and action_name chosen is  right\n",
      "\n",
      "action chosen is  right\n",
      "After get_env_feedback S_ is 2 and R is 0\n",
      "q_predict is  0.0\n",
      "R is 0 and GAMMA is 0.9 and q_table.iloc[S_, :] is left     0.0\n",
      "right    0.0\n",
      "Name: 2, dtype: float64 and q_target will be 0.0\n",
      "S is 1 and A is right and after update q_table.loc[S, A] is 0.000000\n",
      "\n",
      "S is 2 episode is 3 step_counter is 10\n",
      "\n",
      "update_env_else\n",
      "--o--T\n",
      " if state_actions is  left     0.0\n",
      "right    0.0\n",
      "Name: 2, dtype: float64  and action_name chosen is  left\n",
      "\n",
      "action chosen is  left\n",
      "After get_env_feedback S_ is 1 and R is 0\n",
      "q_predict is  0.0\n",
      "R is 0 and GAMMA is 0.9 and q_table.iloc[S_, :] is left     0.0\n",
      "right    0.0\n",
      "Name: 1, dtype: float64 and q_target will be 0.0\n",
      "S is 2 and A is left and after update q_table.loc[S, A] is 0.000000\n",
      "\n",
      "S is 1 episode is 3 step_counter is 11\n",
      "\n",
      "update_env_else\n",
      "-o---T\n",
      " if state_actions is  left     0.0\n",
      "right    0.0\n",
      "Name: 1, dtype: float64  and action_name chosen is  right\n",
      "\n",
      "action chosen is  right\n",
      "After get_env_feedback S_ is 2 and R is 0\n",
      "q_predict is  0.0\n",
      "R is 0 and GAMMA is 0.9 and q_table.iloc[S_, :] is left     0.0\n",
      "right    0.0\n",
      "Name: 2, dtype: float64 and q_target will be 0.0\n",
      "S is 1 and A is right and after update q_table.loc[S, A] is 0.000000\n",
      "\n",
      "S is 2 episode is 3 step_counter is 12\n",
      "\n",
      "update_env_else\n",
      "--o--T\n",
      " if state_actions is  left     0.0\n",
      "right    0.0\n",
      "Name: 2, dtype: float64  and action_name chosen is  left\n",
      "\n",
      "action chosen is  left\n",
      "After get_env_feedback S_ is 1 and R is 0\n",
      "q_predict is  0.0\n",
      "R is 0 and GAMMA is 0.9 and q_table.iloc[S_, :] is left     0.0\n",
      "right    0.0\n",
      "Name: 1, dtype: float64 and q_target will be 0.0\n",
      "S is 2 and A is left and after update q_table.loc[S, A] is 0.000000\n",
      "\n",
      "S is 1 episode is 3 step_counter is 13\n",
      "\n",
      "update_env_else\n",
      "-o---T\n",
      " if state_actions is  left     0.0\n",
      "right    0.0\n",
      "Name: 1, dtype: float64  and action_name chosen is  left\n",
      "\n",
      "action chosen is  left\n",
      "After get_env_feedback S_ is 0 and R is 0\n",
      "q_predict is  0.0\n",
      "R is 0 and GAMMA is 0.9 and q_table.iloc[S_, :] is left     0.0\n",
      "right    0.0\n",
      "Name: 0, dtype: float64 and q_target will be 0.0\n",
      "S is 1 and A is left and after update q_table.loc[S, A] is 0.000000\n",
      "\n",
      "S is 0 episode is 3 step_counter is 14\n",
      "\n",
      "update_env_else\n",
      "o----T\n",
      " if state_actions is  left     0.0\n",
      "right    0.0\n",
      "Name: 0, dtype: float64  and action_name chosen is  left\n",
      "\n",
      "action chosen is  left\n",
      "After get_env_feedback S_ is 0 and R is 0\n",
      "q_predict is  0.0\n",
      "R is 0 and GAMMA is 0.9 and q_table.iloc[S_, :] is left     0.0\n",
      "right    0.0\n",
      "Name: 0, dtype: float64 and q_target will be 0.0\n",
      "S is 0 and A is left and after update q_table.loc[S, A] is 0.000000\n",
      "\n",
      "S is 0 episode is 3 step_counter is 15\n",
      "\n",
      "update_env_else\n",
      "o----T\n",
      " if state_actions is  left     0.0\n",
      "right    0.0\n",
      "Name: 0, dtype: float64  and action_name chosen is  right\n",
      "\n",
      "action chosen is  right\n",
      "After get_env_feedback S_ is 1 and R is 0\n",
      "q_predict is  0.0\n",
      "R is 0 and GAMMA is 0.9 and q_table.iloc[S_, :] is left     0.0\n",
      "right    0.0\n",
      "Name: 1, dtype: float64 and q_target will be 0.0\n",
      "S is 0 and A is right and after update q_table.loc[S, A] is 0.000000\n",
      "\n",
      "S is 1 episode is 3 step_counter is 16\n",
      "\n",
      "update_env_else\n",
      "-o---T\n",
      " if state_actions is  left     0.0\n",
      "right    0.0\n",
      "Name: 1, dtype: float64  and action_name chosen is  right\n",
      "\n",
      "action chosen is  right\n",
      "After get_env_feedback S_ is 2 and R is 0\n",
      "q_predict is  0.0\n",
      "R is 0 and GAMMA is 0.9 and q_table.iloc[S_, :] is left     0.0\n",
      "right    0.0\n",
      "Name: 2, dtype: float64 and q_target will be 0.0\n",
      "S is 1 and A is right and after update q_table.loc[S, A] is 0.000000\n",
      "\n",
      "S is 2 episode is 3 step_counter is 17\n",
      "\n",
      "update_env_else\n",
      "--o--T\n",
      " if state_actions is  left     0.0\n",
      "right    0.0\n",
      "Name: 2, dtype: float64  and action_name chosen is  right\n",
      "\n",
      "action chosen is  right\n",
      "After get_env_feedback S_ is 3 and R is 0\n",
      "q_predict is  0.0\n",
      "R is 0 and GAMMA is 0.9 and q_table.iloc[S_, :] is left     0.0\n",
      "right    0.0\n",
      "Name: 3, dtype: float64 and q_target will be 0.0\n",
      "S is 2 and A is right and after update q_table.loc[S, A] is 0.000000\n",
      "\n",
      "S is 3 episode is 3 step_counter is 18\n",
      "\n",
      "update_env_else\n",
      "---o-T\n",
      " if state_actions is  left     0.0\n",
      "right    0.0\n",
      "Name: 3, dtype: float64  and action_name chosen is  left\n",
      "\n",
      "action chosen is  left\n",
      "After get_env_feedback S_ is 2 and R is 0\n",
      "q_predict is  0.0\n",
      "R is 0 and GAMMA is 0.9 and q_table.iloc[S_, :] is left     0.0\n",
      "right    0.0\n",
      "Name: 2, dtype: float64 and q_target will be 0.0\n",
      "S is 3 and A is left and after update q_table.loc[S, A] is 0.000000\n",
      "\n",
      "S is 2 episode is 3 step_counter is 19\n",
      "\n",
      "update_env_else\n",
      "--o--T\n",
      " if state_actions is  left     0.0\n",
      "right    0.0\n",
      "Name: 2, dtype: float64  and action_name chosen is  left\n",
      "\n",
      "action chosen is  left\n",
      "After get_env_feedback S_ is 1 and R is 0\n",
      "q_predict is  0.0\n",
      "R is 0 and GAMMA is 0.9 and q_table.iloc[S_, :] is left     0.0\n",
      "right    0.0\n",
      "Name: 1, dtype: float64 and q_target will be 0.0\n",
      "S is 2 and A is left and after update q_table.loc[S, A] is 0.000000\n",
      "\n",
      "S is 1 episode is 3 step_counter is 20\n",
      "\n",
      "update_env_else\n",
      "-o---T\n",
      " if state_actions is  left     0.0\n",
      "right    0.0\n",
      "Name: 1, dtype: float64  and action_name chosen is  right\n",
      "\n",
      "action chosen is  right\n",
      "After get_env_feedback S_ is 2 and R is 0\n",
      "q_predict is  0.0\n",
      "R is 0 and GAMMA is 0.9 and q_table.iloc[S_, :] is left     0.0\n",
      "right    0.0\n",
      "Name: 2, dtype: float64 and q_target will be 0.0\n",
      "S is 1 and A is right and after update q_table.loc[S, A] is 0.000000\n",
      "\n",
      "S is 2 episode is 3 step_counter is 21\n",
      "\n",
      "update_env_else\n",
      "--o--T\n",
      " if state_actions is  left     0.0\n",
      "right    0.0\n",
      "Name: 2, dtype: float64  and action_name chosen is  right\n",
      "\n",
      "action chosen is  right\n",
      "After get_env_feedback S_ is 3 and R is 0\n",
      "q_predict is  0.0\n",
      "R is 0 and GAMMA is 0.9 and q_table.iloc[S_, :] is left     0.0\n",
      "right    0.0\n",
      "Name: 3, dtype: float64 and q_target will be 0.0\n",
      "S is 2 and A is right and after update q_table.loc[S, A] is 0.000000\n",
      "\n",
      "S is 3 episode is 3 step_counter is 22\n",
      "\n",
      "update_env_else\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---o-T\n",
      " if state_actions is  left     0.0\n",
      "right    0.0\n",
      "Name: 3, dtype: float64  and action_name chosen is  left\n",
      "\n",
      "action chosen is  left\n",
      "After get_env_feedback S_ is 2 and R is 0\n",
      "q_predict is  0.0\n",
      "R is 0 and GAMMA is 0.9 and q_table.iloc[S_, :] is left     0.0\n",
      "right    0.0\n",
      "Name: 2, dtype: float64 and q_target will be 0.0\n",
      "S is 3 and A is left and after update q_table.loc[S, A] is 0.000000\n",
      "\n",
      "S is 2 episode is 3 step_counter is 23\n",
      "\n",
      "update_env_else\n",
      "--o--T\n",
      " if state_actions is  left     0.0\n",
      "right    0.0\n",
      "Name: 2, dtype: float64  and action_name chosen is  right\n",
      "\n",
      "action chosen is  right\n",
      "After get_env_feedback S_ is 3 and R is 0\n",
      "q_predict is  0.0\n",
      "R is 0 and GAMMA is 0.9 and q_table.iloc[S_, :] is left     0.0\n",
      "right    0.0\n",
      "Name: 3, dtype: float64 and q_target will be 0.0\n",
      "S is 2 and A is right and after update q_table.loc[S, A] is 0.000000\n",
      "\n",
      "S is 3 episode is 3 step_counter is 24\n",
      "\n",
      "update_env_else\n",
      "---o-T\n",
      " if state_actions is  left     0.0\n",
      "right    0.0\n",
      "Name: 3, dtype: float64  and action_name chosen is  right\n",
      "\n",
      "action chosen is  right\n",
      "After get_env_feedback S_ is 4 and R is 0\n",
      "q_predict is  0.0\n",
      "R is 0 and GAMMA is 0.9 and q_table.iloc[S_, :] is left     0.0\n",
      "right    0.0\n",
      "Name: 4, dtype: float64 and q_target will be 0.0\n",
      "S is 3 and A is right and after update q_table.loc[S, A] is 0.000000\n",
      "\n",
      "S is 4 episode is 3 step_counter is 25\n",
      "\n",
      "update_env_else\n",
      "----oT\n",
      " if state_actions is  left     0.0\n",
      "right    0.0\n",
      "Name: 4, dtype: float64  and action_name chosen is  right\n",
      "\n",
      "action chosen is  right\n",
      "After get_env_feedback S_ is terminal and R is 1\n",
      "q_predict is  0.0\n",
      "S is 4 and A is right and after update q_table.loc[S, A] is 0.000000\n",
      "\n",
      "S is terminal episode is 3 step_counter is 26\n",
      "\n",
      "update_env_if\n",
      "Episode 4: total_steps = 26\n",
      "update_env_if\n",
      "                                \n",
      "S is 0 episode is 4 step_counter is 0\n",
      "\n",
      "update_env_else\n",
      "o----T\n",
      " if state_actions is  left     0.0\n",
      "right    0.0\n",
      "Name: 0, dtype: float64  and action_name chosen is  right\n",
      "\n",
      "action chosen is  right\n",
      "After get_env_feedback S_ is 1 and R is 0\n",
      "q_predict is  0.0\n",
      "R is 0 and GAMMA is 0.9 and q_table.iloc[S_, :] is left     0.0\n",
      "right    0.0\n",
      "Name: 1, dtype: float64 and q_target will be 0.0\n",
      "S is 0 and A is right and after update q_table.loc[S, A] is 0.000000\n",
      "\n",
      "S is 1 episode is 4 step_counter is 1\n",
      "\n",
      "update_env_else\n",
      "-o---T\n",
      " if state_actions is  left     0.0\n",
      "right    0.0\n",
      "Name: 1, dtype: float64  and action_name chosen is  left\n",
      "\n",
      "action chosen is  left\n",
      "After get_env_feedback S_ is 0 and R is 0\n",
      "q_predict is  0.0\n",
      "R is 0 and GAMMA is 0.9 and q_table.iloc[S_, :] is left     0.0\n",
      "right    0.0\n",
      "Name: 0, dtype: float64 and q_target will be 0.0\n",
      "S is 1 and A is left and after update q_table.loc[S, A] is 0.000000\n",
      "\n",
      "S is 0 episode is 4 step_counter is 2\n",
      "\n",
      "update_env_else\n",
      "o----T\n",
      " if state_actions is  left     0.0\n",
      "right    0.0\n",
      "Name: 0, dtype: float64  and action_name chosen is  left\n",
      "\n",
      "action chosen is  left\n",
      "After get_env_feedback S_ is 0 and R is 0\n",
      "q_predict is  0.0\n",
      "R is 0 and GAMMA is 0.9 and q_table.iloc[S_, :] is left     0.0\n",
      "right    0.0\n",
      "Name: 0, dtype: float64 and q_target will be 0.0\n",
      "S is 0 and A is left and after update q_table.loc[S, A] is 0.000000\n",
      "\n",
      "S is 0 episode is 4 step_counter is 3\n",
      "\n",
      "update_env_else\n",
      "o----T\n",
      " if state_actions is  left     0.0\n",
      "right    0.0\n",
      "Name: 0, dtype: float64  and action_name chosen is  left\n",
      "\n",
      "action chosen is  left\n",
      "After get_env_feedback S_ is 0 and R is 0\n",
      "q_predict is  0.0\n",
      "R is 0 and GAMMA is 0.9 and q_table.iloc[S_, :] is left     0.0\n",
      "right    0.0\n",
      "Name: 0, dtype: float64 and q_target will be 0.0\n",
      "S is 0 and A is left and after update q_table.loc[S, A] is 0.000000\n",
      "\n",
      "S is 0 episode is 4 step_counter is 4\n",
      "\n",
      "update_env_else\n",
      "o----T\n",
      " if state_actions is  left     0.0\n",
      "right    0.0\n",
      "Name: 0, dtype: float64  and action_name chosen is  left\n",
      "\n",
      "action chosen is  left\n",
      "After get_env_feedback S_ is 0 and R is 0\n",
      "q_predict is  0.0\n",
      "R is 0 and GAMMA is 0.9 and q_table.iloc[S_, :] is left     0.0\n",
      "right    0.0\n",
      "Name: 0, dtype: float64 and q_target will be 0.0\n",
      "S is 0 and A is left and after update q_table.loc[S, A] is 0.000000\n",
      "\n",
      "S is 0 episode is 4 step_counter is 5\n",
      "\n",
      "update_env_else\n",
      "o----T\n",
      " if state_actions is  left     0.0\n",
      "right    0.0\n",
      "Name: 0, dtype: float64  and action_name chosen is  right\n",
      "\n",
      "action chosen is  right\n",
      "After get_env_feedback S_ is 1 and R is 0\n",
      "q_predict is  0.0\n",
      "R is 0 and GAMMA is 0.9 and q_table.iloc[S_, :] is left     0.0\n",
      "right    0.0\n",
      "Name: 1, dtype: float64 and q_target will be 0.0\n",
      "S is 0 and A is right and after update q_table.loc[S, A] is 0.000000\n",
      "\n",
      "S is 1 episode is 4 step_counter is 6\n",
      "\n",
      "update_env_else\n",
      "-o---T\n",
      " if state_actions is  left     0.0\n",
      "right    0.0\n",
      "Name: 1, dtype: float64  and action_name chosen is  right\n",
      "\n",
      "action chosen is  right\n",
      "After get_env_feedback S_ is 2 and R is 0\n",
      "q_predict is  0.0\n",
      "R is 0 and GAMMA is 0.9 and q_table.iloc[S_, :] is left     0.0\n",
      "right    0.0\n",
      "Name: 2, dtype: float64 and q_target will be 0.0\n",
      "S is 1 and A is right and after update q_table.loc[S, A] is 0.000000\n",
      "\n",
      "S is 2 episode is 4 step_counter is 7\n",
      "\n",
      "update_env_else\n",
      "--o--T\n",
      " if state_actions is  left     0.0\n",
      "right    0.0\n",
      "Name: 2, dtype: float64  and action_name chosen is  left\n",
      "\n",
      "action chosen is  left\n",
      "After get_env_feedback S_ is 1 and R is 0\n",
      "q_predict is  0.0\n",
      "R is 0 and GAMMA is 0.9 and q_table.iloc[S_, :] is left     0.0\n",
      "right    0.0\n",
      "Name: 1, dtype: float64 and q_target will be 0.0\n",
      "S is 2 and A is left and after update q_table.loc[S, A] is 0.000000\n",
      "\n",
      "S is 1 episode is 4 step_counter is 8\n",
      "\n",
      "update_env_else\n",
      "-o---T\n",
      " if state_actions is  left     0.0\n",
      "right    0.0\n",
      "Name: 1, dtype: float64  and action_name chosen is  right\n",
      "\n",
      "action chosen is  right\n",
      "After get_env_feedback S_ is 2 and R is 0\n",
      "q_predict is  0.0\n",
      "R is 0 and GAMMA is 0.9 and q_table.iloc[S_, :] is left     0.0\n",
      "right    0.0\n",
      "Name: 2, dtype: float64 and q_target will be 0.0\n",
      "S is 1 and A is right and after update q_table.loc[S, A] is 0.000000\n",
      "\n",
      "S is 2 episode is 4 step_counter is 9\n",
      "\n",
      "update_env_else\n",
      "--o--T\n",
      " if state_actions is  left     0.0\n",
      "right    0.0\n",
      "Name: 2, dtype: float64  and action_name chosen is  right\n",
      "\n",
      "action chosen is  right\n",
      "After get_env_feedback S_ is 3 and R is 0\n",
      "q_predict is  0.0\n",
      "R is 0 and GAMMA is 0.9 and q_table.iloc[S_, :] is left     0.0\n",
      "right    0.0\n",
      "Name: 3, dtype: float64 and q_target will be 0.0\n",
      "S is 2 and A is right and after update q_table.loc[S, A] is 0.000000\n",
      "\n",
      "S is 3 episode is 4 step_counter is 10\n",
      "\n",
      "update_env_else\n",
      "---o-T\n",
      " if state_actions is  left     0.0\n",
      "right    0.0\n",
      "Name: 3, dtype: float64  and action_name chosen is  left\n",
      "\n",
      "action chosen is  left\n",
      "After get_env_feedback S_ is 2 and R is 0\n",
      "q_predict is  0.0\n",
      "R is 0 and GAMMA is 0.9 and q_table.iloc[S_, :] is left     0.0\n",
      "right    0.0\n",
      "Name: 2, dtype: float64 and q_target will be 0.0\n",
      "S is 3 and A is left and after update q_table.loc[S, A] is 0.000000\n",
      "\n",
      "S is 2 episode is 4 step_counter is 11\n",
      "\n",
      "update_env_else\n",
      "--o--T\n",
      " if state_actions is  left     0.0\n",
      "right    0.0\n",
      "Name: 2, dtype: float64  and action_name chosen is  right\n",
      "\n",
      "action chosen is  right\n",
      "After get_env_feedback S_ is 3 and R is 0\n",
      "q_predict is  0.0\n",
      "R is 0 and GAMMA is 0.9 and q_table.iloc[S_, :] is left     0.0\n",
      "right    0.0\n",
      "Name: 3, dtype: float64 and q_target will be 0.0\n",
      "S is 2 and A is right and after update q_table.loc[S, A] is 0.000000\n",
      "\n",
      "S is 3 episode is 4 step_counter is 12\n",
      "\n",
      "update_env_else\n",
      "---o-T\n",
      " if state_actions is  left     0.0\n",
      "right    0.0\n",
      "Name: 3, dtype: float64  and action_name chosen is  right\n",
      "\n",
      "action chosen is  right\n",
      "After get_env_feedback S_ is 4 and R is 0\n",
      "q_predict is  0.0\n",
      "R is 0 and GAMMA is 0.9 and q_table.iloc[S_, :] is left     0.0\n",
      "right    0.0\n",
      "Name: 4, dtype: float64 and q_target will be 0.0\n",
      "S is 3 and A is right and after update q_table.loc[S, A] is 0.000000\n",
      "\n",
      "S is 4 episode is 4 step_counter is 13\n",
      "\n",
      "update_env_else\n",
      "----oT\n",
      " if state_actions is  left     0.0\n",
      "right    0.0\n",
      "Name: 4, dtype: float64  and action_name chosen is  right\n",
      "\n",
      "action chosen is  right\n",
      "After get_env_feedback S_ is terminal and R is 1\n",
      "q_predict is  0.0\n",
      "S is 4 and A is right and after update q_table.loc[S, A] is 0.000000\n",
      "\n",
      "S is terminal episode is 4 step_counter is 14\n",
      "\n",
      "update_env_if\n",
      "Episode 5: total_steps = 14\n",
      "update_env_if\n",
      "                                \n",
      "S is 0 episode is 5 step_counter is 0\n",
      "\n",
      "update_env_else\n",
      "o----T\n",
      " if state_actions is  left     0.0\n",
      "right    0.0\n",
      "Name: 0, dtype: float64  and action_name chosen is  right\n",
      "\n",
      "action chosen is  right\n",
      "After get_env_feedback S_ is 1 and R is 0\n",
      "q_predict is  0.0\n",
      "R is 0 and GAMMA is 0.9 and q_table.iloc[S_, :] is left     0.0\n",
      "right    0.0\n",
      "Name: 1, dtype: float64 and q_target will be 0.0\n",
      "S is 0 and A is right and after update q_table.loc[S, A] is 0.000000\n",
      "\n",
      "S is 1 episode is 5 step_counter is 1\n",
      "\n",
      "update_env_else\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-o---T\n",
      " if state_actions is  left     0.0\n",
      "right    0.0\n",
      "Name: 1, dtype: float64  and action_name chosen is  right\n",
      "\n",
      "action chosen is  right\n",
      "After get_env_feedback S_ is 2 and R is 0\n",
      "q_predict is  0.0\n",
      "R is 0 and GAMMA is 0.9 and q_table.iloc[S_, :] is left     0.0\n",
      "right    0.0\n",
      "Name: 2, dtype: float64 and q_target will be 0.0\n",
      "S is 1 and A is right and after update q_table.loc[S, A] is 0.000000\n",
      "\n",
      "S is 2 episode is 5 step_counter is 2\n",
      "\n",
      "update_env_else\n",
      "--o--T\n",
      " if state_actions is  left     0.0\n",
      "right    0.0\n",
      "Name: 2, dtype: float64  and action_name chosen is  left\n",
      "\n",
      "action chosen is  left\n",
      "After get_env_feedback S_ is 1 and R is 0\n",
      "q_predict is  0.0\n",
      "R is 0 and GAMMA is 0.9 and q_table.iloc[S_, :] is left     0.0\n",
      "right    0.0\n",
      "Name: 1, dtype: float64 and q_target will be 0.0\n",
      "S is 2 and A is left and after update q_table.loc[S, A] is 0.000000\n",
      "\n",
      "S is 1 episode is 5 step_counter is 3\n",
      "\n",
      "update_env_else\n",
      "-o---T\n",
      " if state_actions is  left     0.0\n",
      "right    0.0\n",
      "Name: 1, dtype: float64  and action_name chosen is  left\n",
      "\n",
      "action chosen is  left\n",
      "After get_env_feedback S_ is 0 and R is 0\n",
      "q_predict is  0.0\n",
      "R is 0 and GAMMA is 0.9 and q_table.iloc[S_, :] is left     0.0\n",
      "right    0.0\n",
      "Name: 0, dtype: float64 and q_target will be 0.0\n",
      "S is 1 and A is left and after update q_table.loc[S, A] is 0.000000\n",
      "\n",
      "S is 0 episode is 5 step_counter is 4\n",
      "\n",
      "update_env_else\n",
      "o----T\n",
      " if state_actions is  left     0.0\n",
      "right    0.0\n",
      "Name: 0, dtype: float64  and action_name chosen is  right\n",
      "\n",
      "action chosen is  right\n",
      "After get_env_feedback S_ is 1 and R is 0\n",
      "q_predict is  0.0\n",
      "R is 0 and GAMMA is 0.9 and q_table.iloc[S_, :] is left     0.0\n",
      "right    0.0\n",
      "Name: 1, dtype: float64 and q_target will be 0.0\n",
      "S is 0 and A is right and after update q_table.loc[S, A] is 0.000000\n",
      "\n",
      "S is 1 episode is 5 step_counter is 5\n",
      "\n",
      "update_env_else\n",
      "-o---T\n",
      " if state_actions is  left     0.0\n",
      "right    0.0\n",
      "Name: 1, dtype: float64  and action_name chosen is  left\n",
      "\n",
      "action chosen is  left\n",
      "After get_env_feedback S_ is 0 and R is 0\n",
      "q_predict is  0.0\n",
      "R is 0 and GAMMA is 0.9 and q_table.iloc[S_, :] is left     0.0\n",
      "right    0.0\n",
      "Name: 0, dtype: float64 and q_target will be 0.0\n",
      "S is 1 and A is left and after update q_table.loc[S, A] is 0.000000\n",
      "\n",
      "S is 0 episode is 5 step_counter is 6\n",
      "\n",
      "update_env_else\n",
      "o----T\n",
      " if state_actions is  left     0.0\n",
      "right    0.0\n",
      "Name: 0, dtype: float64  and action_name chosen is  right\n",
      "\n",
      "action chosen is  right\n",
      "After get_env_feedback S_ is 1 and R is 0\n",
      "q_predict is  0.0\n",
      "R is 0 and GAMMA is 0.9 and q_table.iloc[S_, :] is left     0.0\n",
      "right    0.0\n",
      "Name: 1, dtype: float64 and q_target will be 0.0\n",
      "S is 0 and A is right and after update q_table.loc[S, A] is 0.000000\n",
      "\n",
      "S is 1 episode is 5 step_counter is 7\n",
      "\n",
      "update_env_else\n",
      "-o---T\n",
      " if state_actions is  left     0.0\n",
      "right    0.0\n",
      "Name: 1, dtype: float64  and action_name chosen is  left\n",
      "\n",
      "action chosen is  left\n",
      "After get_env_feedback S_ is 0 and R is 0\n",
      "q_predict is  0.0\n",
      "R is 0 and GAMMA is 0.9 and q_table.iloc[S_, :] is left     0.0\n",
      "right    0.0\n",
      "Name: 0, dtype: float64 and q_target will be 0.0\n",
      "S is 1 and A is left and after update q_table.loc[S, A] is 0.000000\n",
      "\n",
      "S is 0 episode is 5 step_counter is 8\n",
      "\n",
      "update_env_else\n",
      "o----T\n",
      " if state_actions is  left     0.0\n",
      "right    0.0\n",
      "Name: 0, dtype: float64  and action_name chosen is  left\n",
      "\n",
      "action chosen is  left\n",
      "After get_env_feedback S_ is 0 and R is 0\n",
      "q_predict is  0.0\n",
      "R is 0 and GAMMA is 0.9 and q_table.iloc[S_, :] is left     0.0\n",
      "right    0.0\n",
      "Name: 0, dtype: float64 and q_target will be 0.0\n",
      "S is 0 and A is left and after update q_table.loc[S, A] is 0.000000\n",
      "\n",
      "S is 0 episode is 5 step_counter is 9\n",
      "\n",
      "update_env_else\n",
      "o----T\n",
      " if state_actions is  left     0.0\n",
      "right    0.0\n",
      "Name: 0, dtype: float64  and action_name chosen is  right\n",
      "\n",
      "action chosen is  right\n",
      "After get_env_feedback S_ is 1 and R is 0\n",
      "q_predict is  0.0\n",
      "R is 0 and GAMMA is 0.9 and q_table.iloc[S_, :] is left     0.0\n",
      "right    0.0\n",
      "Name: 1, dtype: float64 and q_target will be 0.0\n",
      "S is 0 and A is right and after update q_table.loc[S, A] is 0.000000\n",
      "\n",
      "S is 1 episode is 5 step_counter is 10\n",
      "\n",
      "update_env_else\n",
      "-o---T\n",
      " if state_actions is  left     0.0\n",
      "right    0.0\n",
      "Name: 1, dtype: float64  and action_name chosen is  left\n",
      "\n",
      "action chosen is  left\n",
      "After get_env_feedback S_ is 0 and R is 0\n",
      "q_predict is  0.0\n",
      "R is 0 and GAMMA is 0.9 and q_table.iloc[S_, :] is left     0.0\n",
      "right    0.0\n",
      "Name: 0, dtype: float64 and q_target will be 0.0\n",
      "S is 1 and A is left and after update q_table.loc[S, A] is 0.000000\n",
      "\n",
      "S is 0 episode is 5 step_counter is 11\n",
      "\n",
      "update_env_else\n",
      "o----T\n",
      " if state_actions is  left     0.0\n",
      "right    0.0\n",
      "Name: 0, dtype: float64  and action_name chosen is  right\n",
      "\n",
      "action chosen is  right\n",
      "After get_env_feedback S_ is 1 and R is 0\n",
      "q_predict is  0.0\n",
      "R is 0 and GAMMA is 0.9 and q_table.iloc[S_, :] is left     0.0\n",
      "right    0.0\n",
      "Name: 1, dtype: float64 and q_target will be 0.0\n",
      "S is 0 and A is right and after update q_table.loc[S, A] is 0.000000\n",
      "\n",
      "S is 1 episode is 5 step_counter is 12\n",
      "\n",
      "update_env_else\n",
      "-o---T\n",
      " if state_actions is  left     0.0\n",
      "right    0.0\n",
      "Name: 1, dtype: float64  and action_name chosen is  left\n",
      "\n",
      "action chosen is  left\n",
      "After get_env_feedback S_ is 0 and R is 0\n",
      "q_predict is  0.0\n",
      "R is 0 and GAMMA is 0.9 and q_table.iloc[S_, :] is left     0.0\n",
      "right    0.0\n",
      "Name: 0, dtype: float64 and q_target will be 0.0\n",
      "S is 1 and A is left and after update q_table.loc[S, A] is 0.000000\n",
      "\n",
      "S is 0 episode is 5 step_counter is 13\n",
      "\n",
      "update_env_else\n",
      "o----T\n",
      " if state_actions is  left     0.0\n",
      "right    0.0\n",
      "Name: 0, dtype: float64  and action_name chosen is  right\n",
      "\n",
      "action chosen is  right\n",
      "After get_env_feedback S_ is 1 and R is 0\n",
      "q_predict is  0.0\n",
      "R is 0 and GAMMA is 0.9 and q_table.iloc[S_, :] is left     0.0\n",
      "right    0.0\n",
      "Name: 1, dtype: float64 and q_target will be 0.0\n",
      "S is 0 and A is right and after update q_table.loc[S, A] is 0.000000\n",
      "\n",
      "S is 1 episode is 5 step_counter is 14\n",
      "\n",
      "update_env_else\n",
      "-o---T\n",
      " if state_actions is  left     0.0\n",
      "right    0.0\n",
      "Name: 1, dtype: float64  and action_name chosen is  left\n",
      "\n",
      "action chosen is  left\n",
      "After get_env_feedback S_ is 0 and R is 0\n",
      "q_predict is  0.0\n",
      "R is 0 and GAMMA is 0.9 and q_table.iloc[S_, :] is left     0.0\n",
      "right    0.0\n",
      "Name: 0, dtype: float64 and q_target will be 0.0\n",
      "S is 1 and A is left and after update q_table.loc[S, A] is 0.000000\n",
      "\n",
      "S is 0 episode is 5 step_counter is 15\n",
      "\n",
      "update_env_else\n",
      "o----T\n",
      " if state_actions is  left     0.0\n",
      "right    0.0\n",
      "Name: 0, dtype: float64  and action_name chosen is  right\n",
      "\n",
      "action chosen is  right\n",
      "After get_env_feedback S_ is 1 and R is 0\n",
      "q_predict is  0.0\n",
      "R is 0 and GAMMA is 0.9 and q_table.iloc[S_, :] is left     0.0\n",
      "right    0.0\n",
      "Name: 1, dtype: float64 and q_target will be 0.0\n",
      "S is 0 and A is right and after update q_table.loc[S, A] is 0.000000\n",
      "\n",
      "S is 1 episode is 5 step_counter is 16\n",
      "\n",
      "update_env_else\n",
      "-o---T\n",
      " if state_actions is  left     0.0\n",
      "right    0.0\n",
      "Name: 1, dtype: float64  and action_name chosen is  left\n",
      "\n",
      "action chosen is  left\n",
      "After get_env_feedback S_ is 0 and R is 0\n",
      "q_predict is  0.0\n",
      "R is 0 and GAMMA is 0.9 and q_table.iloc[S_, :] is left     0.0\n",
      "right    0.0\n",
      "Name: 0, dtype: float64 and q_target will be 0.0\n",
      "S is 1 and A is left and after update q_table.loc[S, A] is 0.000000\n",
      "\n",
      "S is 0 episode is 5 step_counter is 17\n",
      "\n",
      "update_env_else\n",
      "o----T\n",
      " if state_actions is  left     0.0\n",
      "right    0.0\n",
      "Name: 0, dtype: float64  and action_name chosen is  left\n",
      "\n",
      "action chosen is  left\n",
      "After get_env_feedback S_ is 0 and R is 0\n",
      "q_predict is  0.0\n",
      "R is 0 and GAMMA is 0.9 and q_table.iloc[S_, :] is left     0.0\n",
      "right    0.0\n",
      "Name: 0, dtype: float64 and q_target will be 0.0\n",
      "S is 0 and A is left and after update q_table.loc[S, A] is 0.000000\n",
      "\n",
      "S is 0 episode is 5 step_counter is 18\n",
      "\n",
      "update_env_else\n",
      "o----T\n",
      " if state_actions is  left     0.0\n",
      "right    0.0\n",
      "Name: 0, dtype: float64  and action_name chosen is  right\n",
      "\n",
      "action chosen is  right\n",
      "After get_env_feedback S_ is 1 and R is 0\n",
      "q_predict is  0.0\n",
      "R is 0 and GAMMA is 0.9 and q_table.iloc[S_, :] is left     0.0\n",
      "right    0.0\n",
      "Name: 1, dtype: float64 and q_target will be 0.0\n",
      "S is 0 and A is right and after update q_table.loc[S, A] is 0.000000\n",
      "\n",
      "S is 1 episode is 5 step_counter is 19\n",
      "\n",
      "update_env_else\n",
      "-o---T\n",
      " if state_actions is  left     0.0\n",
      "right    0.0\n",
      "Name: 1, dtype: float64  and action_name chosen is  right\n",
      "\n",
      "action chosen is  right\n",
      "After get_env_feedback S_ is 2 and R is 0\n",
      "q_predict is  0.0\n",
      "R is 0 and GAMMA is 0.9 and q_table.iloc[S_, :] is left     0.0\n",
      "right    0.0\n",
      "Name: 2, dtype: float64 and q_target will be 0.0\n",
      "S is 1 and A is right and after update q_table.loc[S, A] is 0.000000\n",
      "\n",
      "S is 2 episode is 5 step_counter is 20\n",
      "\n",
      "update_env_else\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--o--T\n",
      " if state_actions is  left     0.0\n",
      "right    0.0\n",
      "Name: 2, dtype: float64  and action_name chosen is  right\n",
      "\n",
      "action chosen is  right\n",
      "After get_env_feedback S_ is 3 and R is 0\n",
      "q_predict is  0.0\n",
      "R is 0 and GAMMA is 0.9 and q_table.iloc[S_, :] is left     0.0\n",
      "right    0.0\n",
      "Name: 3, dtype: float64 and q_target will be 0.0\n",
      "S is 2 and A is right and after update q_table.loc[S, A] is 0.000000\n",
      "\n",
      "S is 3 episode is 5 step_counter is 21\n",
      "\n",
      "update_env_else\n",
      "---o-T\n",
      " if state_actions is  left     0.0\n",
      "right    0.0\n",
      "Name: 3, dtype: float64  and action_name chosen is  left\n",
      "\n",
      "action chosen is  left\n",
      "After get_env_feedback S_ is 2 and R is 0\n",
      "q_predict is  0.0\n",
      "R is 0 and GAMMA is 0.9 and q_table.iloc[S_, :] is left     0.0\n",
      "right    0.0\n",
      "Name: 2, dtype: float64 and q_target will be 0.0\n",
      "S is 3 and A is left and after update q_table.loc[S, A] is 0.000000\n",
      "\n",
      "S is 2 episode is 5 step_counter is 22\n",
      "\n",
      "update_env_else\n",
      "--o--T\n",
      " if state_actions is  left     0.0\n",
      "right    0.0\n",
      "Name: 2, dtype: float64  and action_name chosen is  left\n",
      "\n",
      "action chosen is  left\n",
      "After get_env_feedback S_ is 1 and R is 0\n",
      "q_predict is  0.0\n",
      "R is 0 and GAMMA is 0.9 and q_table.iloc[S_, :] is left     0.0\n",
      "right    0.0\n",
      "Name: 1, dtype: float64 and q_target will be 0.0\n",
      "S is 2 and A is left and after update q_table.loc[S, A] is 0.000000\n",
      "\n",
      "S is 1 episode is 5 step_counter is 23\n",
      "\n",
      "update_env_else\n",
      "-o---T\n",
      " if state_actions is  left     0.0\n",
      "right    0.0\n",
      "Name: 1, dtype: float64  and action_name chosen is  left\n",
      "\n",
      "action chosen is  left\n",
      "After get_env_feedback S_ is 0 and R is 0\n",
      "q_predict is  0.0\n",
      "R is 0 and GAMMA is 0.9 and q_table.iloc[S_, :] is left     0.0\n",
      "right    0.0\n",
      "Name: 0, dtype: float64 and q_target will be 0.0\n",
      "S is 1 and A is left and after update q_table.loc[S, A] is 0.000000\n",
      "\n",
      "S is 0 episode is 5 step_counter is 24\n",
      "\n",
      "update_env_else\n",
      "o----T\n",
      " if state_actions is  left     0.0\n",
      "right    0.0\n",
      "Name: 0, dtype: float64  and action_name chosen is  left\n",
      "\n",
      "action chosen is  left\n",
      "After get_env_feedback S_ is 0 and R is 0\n",
      "q_predict is  0.0\n",
      "R is 0 and GAMMA is 0.9 and q_table.iloc[S_, :] is left     0.0\n",
      "right    0.0\n",
      "Name: 0, dtype: float64 and q_target will be 0.0\n",
      "S is 0 and A is left and after update q_table.loc[S, A] is 0.000000\n",
      "\n",
      "S is 0 episode is 5 step_counter is 25\n",
      "\n",
      "update_env_else\n",
      "o----T\n",
      " if state_actions is  left     0.0\n",
      "right    0.0\n",
      "Name: 0, dtype: float64  and action_name chosen is  right\n",
      "\n",
      "action chosen is  right\n",
      "After get_env_feedback S_ is 1 and R is 0\n",
      "q_predict is  0.0\n",
      "R is 0 and GAMMA is 0.9 and q_table.iloc[S_, :] is left     0.0\n",
      "right    0.0\n",
      "Name: 1, dtype: float64 and q_target will be 0.0\n",
      "S is 0 and A is right and after update q_table.loc[S, A] is 0.000000\n",
      "\n",
      "S is 1 episode is 5 step_counter is 26\n",
      "\n",
      "update_env_else\n",
      "-o---T\n",
      " if state_actions is  left     0.0\n",
      "right    0.0\n",
      "Name: 1, dtype: float64  and action_name chosen is  left\n",
      "\n",
      "action chosen is  left\n",
      "After get_env_feedback S_ is 0 and R is 0\n",
      "q_predict is  0.0\n",
      "R is 0 and GAMMA is 0.9 and q_table.iloc[S_, :] is left     0.0\n",
      "right    0.0\n",
      "Name: 0, dtype: float64 and q_target will be 0.0\n",
      "S is 1 and A is left and after update q_table.loc[S, A] is 0.000000\n",
      "\n",
      "S is 0 episode is 5 step_counter is 27\n",
      "\n",
      "update_env_else\n",
      "o----T\n",
      " if state_actions is  left     0.0\n",
      "right    0.0\n",
      "Name: 0, dtype: float64  and action_name chosen is  right\n",
      "\n",
      "action chosen is  right\n",
      "After get_env_feedback S_ is 1 and R is 0\n",
      "q_predict is  0.0\n",
      "R is 0 and GAMMA is 0.9 and q_table.iloc[S_, :] is left     0.0\n",
      "right    0.0\n",
      "Name: 1, dtype: float64 and q_target will be 0.0\n",
      "S is 0 and A is right and after update q_table.loc[S, A] is 0.000000\n",
      "\n",
      "S is 1 episode is 5 step_counter is 28\n",
      "\n",
      "update_env_else\n",
      "-o---T\n",
      " if state_actions is  left     0.0\n",
      "right    0.0\n",
      "Name: 1, dtype: float64  and action_name chosen is  left\n",
      "\n",
      "action chosen is  left\n",
      "After get_env_feedback S_ is 0 and R is 0\n",
      "q_predict is  0.0\n",
      "R is 0 and GAMMA is 0.9 and q_table.iloc[S_, :] is left     0.0\n",
      "right    0.0\n",
      "Name: 0, dtype: float64 and q_target will be 0.0\n",
      "S is 1 and A is left and after update q_table.loc[S, A] is 0.000000\n",
      "\n",
      "S is 0 episode is 5 step_counter is 29\n",
      "\n",
      "update_env_else\n",
      "o----T\n",
      " if state_actions is  left     0.0\n",
      "right    0.0\n",
      "Name: 0, dtype: float64  and action_name chosen is  right\n",
      "\n",
      "action chosen is  right\n",
      "After get_env_feedback S_ is 1 and R is 0\n",
      "q_predict is  0.0\n",
      "R is 0 and GAMMA is 0.9 and q_table.iloc[S_, :] is left     0.0\n",
      "right    0.0\n",
      "Name: 1, dtype: float64 and q_target will be 0.0\n",
      "S is 0 and A is right and after update q_table.loc[S, A] is 0.000000\n",
      "\n",
      "S is 1 episode is 5 step_counter is 30\n",
      "\n",
      "update_env_else\n",
      "-o---T\n",
      " if state_actions is  left     0.0\n",
      "right    0.0\n",
      "Name: 1, dtype: float64  and action_name chosen is  right\n",
      "\n",
      "action chosen is  right\n",
      "After get_env_feedback S_ is 2 and R is 0\n",
      "q_predict is  0.0\n",
      "R is 0 and GAMMA is 0.9 and q_table.iloc[S_, :] is left     0.0\n",
      "right    0.0\n",
      "Name: 2, dtype: float64 and q_target will be 0.0\n",
      "S is 1 and A is right and after update q_table.loc[S, A] is 0.000000\n",
      "\n",
      "S is 2 episode is 5 step_counter is 31\n",
      "\n",
      "update_env_else\n",
      "--o--T\n",
      " if state_actions is  left     0.0\n",
      "right    0.0\n",
      "Name: 2, dtype: float64  and action_name chosen is  right\n",
      "\n",
      "action chosen is  right\n",
      "After get_env_feedback S_ is 3 and R is 0\n",
      "q_predict is  0.0\n",
      "R is 0 and GAMMA is 0.9 and q_table.iloc[S_, :] is left     0.0\n",
      "right    0.0\n",
      "Name: 3, dtype: float64 and q_target will be 0.0\n",
      "S is 2 and A is right and after update q_table.loc[S, A] is 0.000000\n",
      "\n",
      "S is 3 episode is 5 step_counter is 32\n",
      "\n",
      "update_env_else\n",
      "---o-T\n",
      " if state_actions is  left     0.0\n",
      "right    0.0\n",
      "Name: 3, dtype: float64  and action_name chosen is  right\n",
      "\n",
      "action chosen is  right\n",
      "After get_env_feedback S_ is 4 and R is 0\n",
      "q_predict is  0.0\n",
      "R is 0 and GAMMA is 0.9 and q_table.iloc[S_, :] is left     0.0\n",
      "right    0.0\n",
      "Name: 4, dtype: float64 and q_target will be 0.0\n",
      "S is 3 and A is right and after update q_table.loc[S, A] is 0.000000\n",
      "\n",
      "S is 4 episode is 5 step_counter is 33\n",
      "\n",
      "update_env_else\n",
      "----oT\n",
      " if state_actions is  left     0.0\n",
      "right    0.0\n",
      "Name: 4, dtype: float64  and action_name chosen is  right\n",
      "\n",
      "action chosen is  right\n",
      "After get_env_feedback S_ is terminal and R is 1\n",
      "q_predict is  0.0\n",
      "S is 4 and A is right and after update q_table.loc[S, A] is 0.000000\n",
      "\n",
      "S is terminal episode is 5 step_counter is 34\n",
      "\n",
      "update_env_if\n",
      "Episode 6: total_steps = 34\n",
      "update_env_if\n",
      "                                \n",
      "S is 0 episode is 6 step_counter is 0\n",
      "\n",
      "update_env_else\n",
      "o----T\n",
      " if state_actions is  left     0.0\n",
      "right    0.0\n",
      "Name: 0, dtype: float64  and action_name chosen is  right\n",
      "\n",
      "action chosen is  right\n",
      "After get_env_feedback S_ is 1 and R is 0\n",
      "q_predict is  0.0\n",
      "R is 0 and GAMMA is 0.9 and q_table.iloc[S_, :] is left     0.0\n",
      "right    0.0\n",
      "Name: 1, dtype: float64 and q_target will be 0.0\n",
      "S is 0 and A is right and after update q_table.loc[S, A] is 0.000000\n",
      "\n",
      "S is 1 episode is 6 step_counter is 1\n",
      "\n",
      "update_env_else\n",
      "-o---T\n",
      " if state_actions is  left     0.0\n",
      "right    0.0\n",
      "Name: 1, dtype: float64  and action_name chosen is  left\n",
      "\n",
      "action chosen is  left\n",
      "After get_env_feedback S_ is 0 and R is 0\n",
      "q_predict is  0.0\n",
      "R is 0 and GAMMA is 0.9 and q_table.iloc[S_, :] is left     0.0\n",
      "right    0.0\n",
      "Name: 0, dtype: float64 and q_target will be 0.0\n",
      "S is 1 and A is left and after update q_table.loc[S, A] is 0.000000\n",
      "\n",
      "S is 0 episode is 6 step_counter is 2\n",
      "\n",
      "update_env_else\n",
      "o----T\n",
      " if state_actions is  left     0.0\n",
      "right    0.0\n",
      "Name: 0, dtype: float64  and action_name chosen is  left\n",
      "\n",
      "action chosen is  left\n",
      "After get_env_feedback S_ is 0 and R is 0\n",
      "q_predict is  0.0\n",
      "R is 0 and GAMMA is 0.9 and q_table.iloc[S_, :] is left     0.0\n",
      "right    0.0\n",
      "Name: 0, dtype: float64 and q_target will be 0.0\n",
      "S is 0 and A is left and after update q_table.loc[S, A] is 0.000000\n",
      "\n",
      "S is 0 episode is 6 step_counter is 3\n",
      "\n",
      "update_env_else\n",
      "o----T\n",
      " if state_actions is  left     0.0\n",
      "right    0.0\n",
      "Name: 0, dtype: float64  and action_name chosen is  right\n",
      "\n",
      "action chosen is  right\n",
      "After get_env_feedback S_ is 1 and R is 0\n",
      "q_predict is  0.0\n",
      "R is 0 and GAMMA is 0.9 and q_table.iloc[S_, :] is left     0.0\n",
      "right    0.0\n",
      "Name: 1, dtype: float64 and q_target will be 0.0\n",
      "S is 0 and A is right and after update q_table.loc[S, A] is 0.000000\n",
      "\n",
      "S is 1 episode is 6 step_counter is 4\n",
      "\n",
      "update_env_else\n",
      "-o---T\n",
      " if state_actions is  left     0.0\n",
      "right    0.0\n",
      "Name: 1, dtype: float64  and action_name chosen is  right\n",
      "\n",
      "action chosen is  right\n",
      "After get_env_feedback S_ is 2 and R is 0\n",
      "q_predict is  0.0\n",
      "R is 0 and GAMMA is 0.9 and q_table.iloc[S_, :] is left     0.0\n",
      "right    0.0\n",
      "Name: 2, dtype: float64 and q_target will be 0.0\n",
      "S is 1 and A is right and after update q_table.loc[S, A] is 0.000000\n",
      "\n",
      "S is 2 episode is 6 step_counter is 5\n",
      "\n",
      "update_env_else\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--o--T\n",
      " if state_actions is  left     0.0\n",
      "right    0.0\n",
      "Name: 2, dtype: float64  and action_name chosen is  right\n",
      "\n",
      "action chosen is  right\n",
      "After get_env_feedback S_ is 3 and R is 0\n",
      "q_predict is  0.0\n",
      "R is 0 and GAMMA is 0.9 and q_table.iloc[S_, :] is left     0.0\n",
      "right    0.0\n",
      "Name: 3, dtype: float64 and q_target will be 0.0\n",
      "S is 2 and A is right and after update q_table.loc[S, A] is 0.000000\n",
      "\n",
      "S is 3 episode is 6 step_counter is 6\n",
      "\n",
      "update_env_else\n",
      "---o-T\n",
      " if state_actions is  left     0.0\n",
      "right    0.0\n",
      "Name: 3, dtype: float64  and action_name chosen is  left\n",
      "\n",
      "action chosen is  left\n",
      "After get_env_feedback S_ is 2 and R is 0\n",
      "q_predict is  0.0\n",
      "R is 0 and GAMMA is 0.9 and q_table.iloc[S_, :] is left     0.0\n",
      "right    0.0\n",
      "Name: 2, dtype: float64 and q_target will be 0.0\n",
      "S is 3 and A is left and after update q_table.loc[S, A] is 0.000000\n",
      "\n",
      "S is 2 episode is 6 step_counter is 7\n",
      "\n",
      "update_env_else\n",
      "--o--T\n",
      " if state_actions is  left     0.0\n",
      "right    0.0\n",
      "Name: 2, dtype: float64  and action_name chosen is  left\n",
      "\n",
      "action chosen is  left\n",
      "After get_env_feedback S_ is 1 and R is 0\n",
      "q_predict is  0.0\n",
      "R is 0 and GAMMA is 0.9 and q_table.iloc[S_, :] is left     0.0\n",
      "right    0.0\n",
      "Name: 1, dtype: float64 and q_target will be 0.0\n",
      "S is 2 and A is left and after update q_table.loc[S, A] is 0.000000\n",
      "\n",
      "S is 1 episode is 6 step_counter is 8\n",
      "\n",
      "update_env_else\n",
      "-o---T\n",
      " if state_actions is  left     0.0\n",
      "right    0.0\n",
      "Name: 1, dtype: float64  and action_name chosen is  left\n",
      "\n",
      "action chosen is  left\n",
      "After get_env_feedback S_ is 0 and R is 0\n",
      "q_predict is  0.0\n",
      "R is 0 and GAMMA is 0.9 and q_table.iloc[S_, :] is left     0.0\n",
      "right    0.0\n",
      "Name: 0, dtype: float64 and q_target will be 0.0\n",
      "S is 1 and A is left and after update q_table.loc[S, A] is 0.000000\n",
      "\n",
      "S is 0 episode is 6 step_counter is 9\n",
      "\n",
      "update_env_else\n",
      "o----T\n",
      " if state_actions is  left     0.0\n",
      "right    0.0\n",
      "Name: 0, dtype: float64  and action_name chosen is  right\n",
      "\n",
      "action chosen is  right\n",
      "After get_env_feedback S_ is 1 and R is 0\n",
      "q_predict is  0.0\n",
      "R is 0 and GAMMA is 0.9 and q_table.iloc[S_, :] is left     0.0\n",
      "right    0.0\n",
      "Name: 1, dtype: float64 and q_target will be 0.0\n",
      "S is 0 and A is right and after update q_table.loc[S, A] is 0.000000\n",
      "\n",
      "S is 1 episode is 6 step_counter is 10\n",
      "\n",
      "update_env_else\n",
      "-o---T\n",
      " if state_actions is  left     0.0\n",
      "right    0.0\n",
      "Name: 1, dtype: float64  and action_name chosen is  right\n",
      "\n",
      "action chosen is  right\n",
      "After get_env_feedback S_ is 2 and R is 0\n",
      "q_predict is  0.0\n",
      "R is 0 and GAMMA is 0.9 and q_table.iloc[S_, :] is left     0.0\n",
      "right    0.0\n",
      "Name: 2, dtype: float64 and q_target will be 0.0\n",
      "S is 1 and A is right and after update q_table.loc[S, A] is 0.000000\n",
      "\n",
      "S is 2 episode is 6 step_counter is 11\n",
      "\n",
      "update_env_else\n",
      "--o--T\n",
      " if state_actions is  left     0.0\n",
      "right    0.0\n",
      "Name: 2, dtype: float64  and action_name chosen is  right\n",
      "\n",
      "action chosen is  right\n",
      "After get_env_feedback S_ is 3 and R is 0\n",
      "q_predict is  0.0\n",
      "R is 0 and GAMMA is 0.9 and q_table.iloc[S_, :] is left     0.0\n",
      "right    0.0\n",
      "Name: 3, dtype: float64 and q_target will be 0.0\n",
      "S is 2 and A is right and after update q_table.loc[S, A] is 0.000000\n",
      "\n",
      "S is 3 episode is 6 step_counter is 12\n",
      "\n",
      "update_env_else\n",
      "---o-T\n",
      " if state_actions is  left     0.0\n",
      "right    0.0\n",
      "Name: 3, dtype: float64  and action_name chosen is  left\n",
      "\n",
      "action chosen is  left\n",
      "After get_env_feedback S_ is 2 and R is 0\n",
      "q_predict is  0.0\n",
      "R is 0 and GAMMA is 0.9 and q_table.iloc[S_, :] is left     0.0\n",
      "right    0.0\n",
      "Name: 2, dtype: float64 and q_target will be 0.0\n",
      "S is 3 and A is left and after update q_table.loc[S, A] is 0.000000\n",
      "\n",
      "S is 2 episode is 6 step_counter is 13\n",
      "\n",
      "update_env_else\n",
      "--o--T\n",
      " if state_actions is  left     0.0\n",
      "right    0.0\n",
      "Name: 2, dtype: float64  and action_name chosen is  left\n",
      "\n",
      "action chosen is  left\n",
      "After get_env_feedback S_ is 1 and R is 0\n",
      "q_predict is  0.0\n",
      "R is 0 and GAMMA is 0.9 and q_table.iloc[S_, :] is left     0.0\n",
      "right    0.0\n",
      "Name: 1, dtype: float64 and q_target will be 0.0\n",
      "S is 2 and A is left and after update q_table.loc[S, A] is 0.000000\n",
      "\n",
      "S is 1 episode is 6 step_counter is 14\n",
      "\n",
      "update_env_else\n",
      "-o---T\n",
      " if state_actions is  left     0.0\n",
      "right    0.0\n",
      "Name: 1, dtype: float64  and action_name chosen is  left\n",
      "\n",
      "action chosen is  left\n",
      "After get_env_feedback S_ is 0 and R is 0\n",
      "q_predict is  0.0\n",
      "R is 0 and GAMMA is 0.9 and q_table.iloc[S_, :] is left     0.0\n",
      "right    0.0\n",
      "Name: 0, dtype: float64 and q_target will be 0.0\n",
      "S is 1 and A is left and after update q_table.loc[S, A] is 0.000000\n",
      "\n",
      "S is 0 episode is 6 step_counter is 15\n",
      "\n",
      "update_env_else\n",
      "o----T\n",
      " if state_actions is  left     0.0\n",
      "right    0.0\n",
      "Name: 0, dtype: float64  and action_name chosen is  left\n",
      "\n",
      "action chosen is  left\n",
      "After get_env_feedback S_ is 0 and R is 0\n",
      "q_predict is  0.0\n",
      "R is 0 and GAMMA is 0.9 and q_table.iloc[S_, :] is left     0.0\n",
      "right    0.0\n",
      "Name: 0, dtype: float64 and q_target will be 0.0\n",
      "S is 0 and A is left and after update q_table.loc[S, A] is 0.000000\n",
      "\n",
      "S is 0 episode is 6 step_counter is 16\n",
      "\n",
      "update_env_else\n",
      "o----T\n",
      " if state_actions is  left     0.0\n",
      "right    0.0\n",
      "Name: 0, dtype: float64  and action_name chosen is  right\n",
      "\n",
      "action chosen is  right\n",
      "After get_env_feedback S_ is 1 and R is 0\n",
      "q_predict is  0.0\n",
      "R is 0 and GAMMA is 0.9 and q_table.iloc[S_, :] is left     0.0\n",
      "right    0.0\n",
      "Name: 1, dtype: float64 and q_target will be 0.0\n",
      "S is 0 and A is right and after update q_table.loc[S, A] is 0.000000\n",
      "\n",
      "S is 1 episode is 6 step_counter is 17\n",
      "\n",
      "update_env_else\n",
      "-o---T\n",
      " if state_actions is  left     0.0\n",
      "right    0.0\n",
      "Name: 1, dtype: float64  and action_name chosen is  right\n",
      "\n",
      "action chosen is  right\n",
      "After get_env_feedback S_ is 2 and R is 0\n",
      "q_predict is  0.0\n",
      "R is 0 and GAMMA is 0.9 and q_table.iloc[S_, :] is left     0.0\n",
      "right    0.0\n",
      "Name: 2, dtype: float64 and q_target will be 0.0\n",
      "S is 1 and A is right and after update q_table.loc[S, A] is 0.000000\n",
      "\n",
      "S is 2 episode is 6 step_counter is 18\n",
      "\n",
      "update_env_else\n",
      "--o--T\n",
      " if state_actions is  left     0.0\n",
      "right    0.0\n",
      "Name: 2, dtype: float64  and action_name chosen is  left\n",
      "\n",
      "action chosen is  left\n",
      "After get_env_feedback S_ is 1 and R is 0\n",
      "q_predict is  0.0\n",
      "R is 0 and GAMMA is 0.9 and q_table.iloc[S_, :] is left     0.0\n",
      "right    0.0\n",
      "Name: 1, dtype: float64 and q_target will be 0.0\n",
      "S is 2 and A is left and after update q_table.loc[S, A] is 0.000000\n",
      "\n",
      "S is 1 episode is 6 step_counter is 19\n",
      "\n",
      "update_env_else\n",
      "-o---T\n",
      " if state_actions is  left     0.0\n",
      "right    0.0\n",
      "Name: 1, dtype: float64  and action_name chosen is  right\n",
      "\n",
      "action chosen is  right\n",
      "After get_env_feedback S_ is 2 and R is 0\n",
      "q_predict is  0.0\n",
      "R is 0 and GAMMA is 0.9 and q_table.iloc[S_, :] is left     0.0\n",
      "right    0.0\n",
      "Name: 2, dtype: float64 and q_target will be 0.0\n",
      "S is 1 and A is right and after update q_table.loc[S, A] is 0.000000\n",
      "\n",
      "S is 2 episode is 6 step_counter is 20\n",
      "\n",
      "update_env_else\n",
      "--o--T\n",
      " if state_actions is  left     0.0\n",
      "right    0.0\n",
      "Name: 2, dtype: float64  and action_name chosen is  left\n",
      "\n",
      "action chosen is  left\n",
      "After get_env_feedback S_ is 1 and R is 0\n",
      "q_predict is  0.0\n",
      "R is 0 and GAMMA is 0.9 and q_table.iloc[S_, :] is left     0.0\n",
      "right    0.0\n",
      "Name: 1, dtype: float64 and q_target will be 0.0\n",
      "S is 2 and A is left and after update q_table.loc[S, A] is 0.000000\n",
      "\n",
      "S is 1 episode is 6 step_counter is 21\n",
      "\n",
      "update_env_else\n",
      "-o---T\n",
      " if state_actions is  left     0.0\n",
      "right    0.0\n",
      "Name: 1, dtype: float64  and action_name chosen is  right\n",
      "\n",
      "action chosen is  right\n",
      "After get_env_feedback S_ is 2 and R is 0\n",
      "q_predict is  0.0\n",
      "R is 0 and GAMMA is 0.9 and q_table.iloc[S_, :] is left     0.0\n",
      "right    0.0\n",
      "Name: 2, dtype: float64 and q_target will be 0.0\n",
      "S is 1 and A is right and after update q_table.loc[S, A] is 0.000000\n",
      "\n",
      "S is 2 episode is 6 step_counter is 22\n",
      "\n",
      "update_env_else\n",
      "--o--T\n",
      " if state_actions is  left     0.0\n",
      "right    0.0\n",
      "Name: 2, dtype: float64  and action_name chosen is  left\n",
      "\n",
      "action chosen is  left\n",
      "After get_env_feedback S_ is 1 and R is 0\n",
      "q_predict is  0.0\n",
      "R is 0 and GAMMA is 0.9 and q_table.iloc[S_, :] is left     0.0\n",
      "right    0.0\n",
      "Name: 1, dtype: float64 and q_target will be 0.0\n",
      "S is 2 and A is left and after update q_table.loc[S, A] is 0.000000\n",
      "\n",
      "S is 1 episode is 6 step_counter is 23\n",
      "\n",
      "update_env_else\n",
      "-o---T\n",
      " if state_actions is  left     0.0\n",
      "right    0.0\n",
      "Name: 1, dtype: float64  and action_name chosen is  right\n",
      "\n",
      "action chosen is  right\n",
      "After get_env_feedback S_ is 2 and R is 0\n",
      "q_predict is  0.0\n",
      "R is 0 and GAMMA is 0.9 and q_table.iloc[S_, :] is left     0.0\n",
      "right    0.0\n",
      "Name: 2, dtype: float64 and q_target will be 0.0\n",
      "S is 1 and A is right and after update q_table.loc[S, A] is 0.000000\n",
      "\n",
      "S is 2 episode is 6 step_counter is 24\n",
      "\n",
      "update_env_else\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--o--T\n",
      " if state_actions is  left     0.0\n",
      "right    0.0\n",
      "Name: 2, dtype: float64  and action_name chosen is  right\n",
      "\n",
      "action chosen is  right\n",
      "After get_env_feedback S_ is 3 and R is 0\n",
      "q_predict is  0.0\n",
      "R is 0 and GAMMA is 0.9 and q_table.iloc[S_, :] is left     0.0\n",
      "right    0.0\n",
      "Name: 3, dtype: float64 and q_target will be 0.0\n",
      "S is 2 and A is right and after update q_table.loc[S, A] is 0.000000\n",
      "\n",
      "S is 3 episode is 6 step_counter is 25\n",
      "\n",
      "update_env_else\n",
      "---o-T\n",
      " if state_actions is  left     0.0\n",
      "right    0.0\n",
      "Name: 3, dtype: float64  and action_name chosen is  right\n",
      "\n",
      "action chosen is  right\n",
      "After get_env_feedback S_ is 4 and R is 0\n",
      "q_predict is  0.0\n",
      "R is 0 and GAMMA is 0.9 and q_table.iloc[S_, :] is left     0.0\n",
      "right    0.0\n",
      "Name: 4, dtype: float64 and q_target will be 0.0\n",
      "S is 3 and A is right and after update q_table.loc[S, A] is 0.000000\n",
      "\n",
      "S is 4 episode is 6 step_counter is 26\n",
      "\n",
      "update_env_else\n",
      "----oT\n",
      " if state_actions is  left     0.0\n",
      "right    0.0\n",
      "Name: 4, dtype: float64  and action_name chosen is  left\n",
      "\n",
      "action chosen is  left\n",
      "After get_env_feedback S_ is 3 and R is 0\n",
      "q_predict is  0.0\n",
      "R is 0 and GAMMA is 0.9 and q_table.iloc[S_, :] is left     0.0\n",
      "right    0.0\n",
      "Name: 3, dtype: float64 and q_target will be 0.0\n",
      "S is 4 and A is left and after update q_table.loc[S, A] is 0.000000\n",
      "\n",
      "S is 3 episode is 6 step_counter is 27\n",
      "\n",
      "update_env_else\n",
      "---o-T\n",
      " if state_actions is  left     0.0\n",
      "right    0.0\n",
      "Name: 3, dtype: float64  and action_name chosen is  left\n",
      "\n",
      "action chosen is  left\n",
      "After get_env_feedback S_ is 2 and R is 0\n",
      "q_predict is  0.0\n",
      "R is 0 and GAMMA is 0.9 and q_table.iloc[S_, :] is left     0.0\n",
      "right    0.0\n",
      "Name: 2, dtype: float64 and q_target will be 0.0\n",
      "S is 3 and A is left and after update q_table.loc[S, A] is 0.000000\n",
      "\n",
      "S is 2 episode is 6 step_counter is 28\n",
      "\n",
      "update_env_else\n",
      "--o--T\n",
      " if state_actions is  left     0.0\n",
      "right    0.0\n",
      "Name: 2, dtype: float64  and action_name chosen is  left\n",
      "\n",
      "action chosen is  left\n",
      "After get_env_feedback S_ is 1 and R is 0\n",
      "q_predict is  0.0\n",
      "R is 0 and GAMMA is 0.9 and q_table.iloc[S_, :] is left     0.0\n",
      "right    0.0\n",
      "Name: 1, dtype: float64 and q_target will be 0.0\n",
      "S is 2 and A is left and after update q_table.loc[S, A] is 0.000000\n",
      "\n",
      "S is 1 episode is 6 step_counter is 29\n",
      "\n",
      "update_env_else\n",
      "-o---T\n",
      " if state_actions is  left     0.0\n",
      "right    0.0\n",
      "Name: 1, dtype: float64  and action_name chosen is  left\n",
      "\n",
      "action chosen is  left\n",
      "After get_env_feedback S_ is 0 and R is 0\n",
      "q_predict is  0.0\n",
      "R is 0 and GAMMA is 0.9 and q_table.iloc[S_, :] is left     0.0\n",
      "right    0.0\n",
      "Name: 0, dtype: float64 and q_target will be 0.0\n",
      "S is 1 and A is left and after update q_table.loc[S, A] is 0.000000\n",
      "\n",
      "S is 0 episode is 6 step_counter is 30\n",
      "\n",
      "update_env_else\n",
      "o----T\n",
      " if state_actions is  left     0.0\n",
      "right    0.0\n",
      "Name: 0, dtype: float64  and action_name chosen is  right\n",
      "\n",
      "action chosen is  right\n",
      "After get_env_feedback S_ is 1 and R is 0\n",
      "q_predict is  0.0\n",
      "R is 0 and GAMMA is 0.9 and q_table.iloc[S_, :] is left     0.0\n",
      "right    0.0\n",
      "Name: 1, dtype: float64 and q_target will be 0.0\n",
      "S is 0 and A is right and after update q_table.loc[S, A] is 0.000000\n",
      "\n",
      "S is 1 episode is 6 step_counter is 31\n",
      "\n",
      "update_env_else\n",
      "-o---T\n",
      " if state_actions is  left     0.0\n",
      "right    0.0\n",
      "Name: 1, dtype: float64  and action_name chosen is  left\n",
      "\n",
      "action chosen is  left\n",
      "After get_env_feedback S_ is 0 and R is 0\n",
      "q_predict is  0.0\n",
      "R is 0 and GAMMA is 0.9 and q_table.iloc[S_, :] is left     0.0\n",
      "right    0.0\n",
      "Name: 0, dtype: float64 and q_target will be 0.0\n",
      "S is 1 and A is left and after update q_table.loc[S, A] is 0.000000\n",
      "\n",
      "S is 0 episode is 6 step_counter is 32\n",
      "\n",
      "update_env_else\n",
      "o----T\n",
      " if state_actions is  left     0.0\n",
      "right    0.0\n",
      "Name: 0, dtype: float64  and action_name chosen is  left\n",
      "\n",
      "action chosen is  left\n",
      "After get_env_feedback S_ is 0 and R is 0\n",
      "q_predict is  0.0\n",
      "R is 0 and GAMMA is 0.9 and q_table.iloc[S_, :] is left     0.0\n",
      "right    0.0\n",
      "Name: 0, dtype: float64 and q_target will be 0.0\n",
      "S is 0 and A is left and after update q_table.loc[S, A] is 0.000000\n",
      "\n",
      "S is 0 episode is 6 step_counter is 33\n",
      "\n",
      "update_env_else\n",
      "o----T\n",
      " if state_actions is  left     0.0\n",
      "right    0.0\n",
      "Name: 0, dtype: float64  and action_name chosen is  right\n",
      "\n",
      "action chosen is  right\n",
      "After get_env_feedback S_ is 1 and R is 0\n",
      "q_predict is  0.0\n",
      "R is 0 and GAMMA is 0.9 and q_table.iloc[S_, :] is left     0.0\n",
      "right    0.0\n",
      "Name: 1, dtype: float64 and q_target will be 0.0\n",
      "S is 0 and A is right and after update q_table.loc[S, A] is 0.000000\n",
      "\n",
      "S is 1 episode is 6 step_counter is 34\n",
      "\n",
      "update_env_else\n",
      "-o---T\n",
      " if state_actions is  left     0.0\n",
      "right    0.0\n",
      "Name: 1, dtype: float64  and action_name chosen is  left\n",
      "\n",
      "action chosen is  left\n",
      "After get_env_feedback S_ is 0 and R is 0\n",
      "q_predict is  0.0\n",
      "R is 0 and GAMMA is 0.9 and q_table.iloc[S_, :] is left     0.0\n",
      "right    0.0\n",
      "Name: 0, dtype: float64 and q_target will be 0.0\n",
      "S is 1 and A is left and after update q_table.loc[S, A] is 0.000000\n",
      "\n",
      "S is 0 episode is 6 step_counter is 35\n",
      "\n",
      "update_env_else\n",
      "o----T\n",
      " if state_actions is  left     0.0\n",
      "right    0.0\n",
      "Name: 0, dtype: float64  and action_name chosen is  left\n",
      "\n",
      "action chosen is  left\n",
      "After get_env_feedback S_ is 0 and R is 0\n",
      "q_predict is  0.0\n",
      "R is 0 and GAMMA is 0.9 and q_table.iloc[S_, :] is left     0.0\n",
      "right    0.0\n",
      "Name: 0, dtype: float64 and q_target will be 0.0\n",
      "S is 0 and A is left and after update q_table.loc[S, A] is 0.000000\n",
      "\n",
      "S is 0 episode is 6 step_counter is 36\n",
      "\n",
      "update_env_else\n",
      "o----T\n",
      " if state_actions is  left     0.0\n",
      "right    0.0\n",
      "Name: 0, dtype: float64  and action_name chosen is  right\n",
      "\n",
      "action chosen is  right\n",
      "After get_env_feedback S_ is 1 and R is 0\n",
      "q_predict is  0.0\n",
      "R is 0 and GAMMA is 0.9 and q_table.iloc[S_, :] is left     0.0\n",
      "right    0.0\n",
      "Name: 1, dtype: float64 and q_target will be 0.0\n",
      "S is 0 and A is right and after update q_table.loc[S, A] is 0.000000\n",
      "\n",
      "S is 1 episode is 6 step_counter is 37\n",
      "\n",
      "update_env_else\n",
      "-o---T\n",
      " if state_actions is  left     0.0\n",
      "right    0.0\n",
      "Name: 1, dtype: float64  and action_name chosen is  right\n",
      "\n",
      "action chosen is  right\n",
      "After get_env_feedback S_ is 2 and R is 0\n",
      "q_predict is  0.0\n",
      "R is 0 and GAMMA is 0.9 and q_table.iloc[S_, :] is left     0.0\n",
      "right    0.0\n",
      "Name: 2, dtype: float64 and q_target will be 0.0\n",
      "S is 1 and A is right and after update q_table.loc[S, A] is 0.000000\n",
      "\n",
      "S is 2 episode is 6 step_counter is 38\n",
      "\n",
      "update_env_else\n",
      "--o--T\n",
      " if state_actions is  left     0.0\n",
      "right    0.0\n",
      "Name: 2, dtype: float64  and action_name chosen is  left\n",
      "\n",
      "action chosen is  left\n",
      "After get_env_feedback S_ is 1 and R is 0\n",
      "q_predict is  0.0\n",
      "R is 0 and GAMMA is 0.9 and q_table.iloc[S_, :] is left     0.0\n",
      "right    0.0\n",
      "Name: 1, dtype: float64 and q_target will be 0.0\n",
      "S is 2 and A is left and after update q_table.loc[S, A] is 0.000000\n",
      "\n",
      "S is 1 episode is 6 step_counter is 39\n",
      "\n",
      "update_env_else\n",
      "-o---T\n",
      " if state_actions is  left     0.0\n",
      "right    0.0\n",
      "Name: 1, dtype: float64  and action_name chosen is  right\n",
      "\n",
      "action chosen is  right\n",
      "After get_env_feedback S_ is 2 and R is 0\n",
      "q_predict is  0.0\n",
      "R is 0 and GAMMA is 0.9 and q_table.iloc[S_, :] is left     0.0\n",
      "right    0.0\n",
      "Name: 2, dtype: float64 and q_target will be 0.0\n",
      "S is 1 and A is right and after update q_table.loc[S, A] is 0.000000\n",
      "\n",
      "S is 2 episode is 6 step_counter is 40\n",
      "\n",
      "update_env_else\n",
      "--o--T\n",
      " if state_actions is  left     0.0\n",
      "right    0.0\n",
      "Name: 2, dtype: float64  and action_name chosen is  left\n",
      "\n",
      "action chosen is  left\n",
      "After get_env_feedback S_ is 1 and R is 0\n",
      "q_predict is  0.0\n",
      "R is 0 and GAMMA is 0.9 and q_table.iloc[S_, :] is left     0.0\n",
      "right    0.0\n",
      "Name: 1, dtype: float64 and q_target will be 0.0\n",
      "S is 2 and A is left and after update q_table.loc[S, A] is 0.000000\n",
      "\n",
      "S is 1 episode is 6 step_counter is 41\n",
      "\n",
      "update_env_else\n",
      "-o---T\n",
      " if state_actions is  left     0.0\n",
      "right    0.0\n",
      "Name: 1, dtype: float64  and action_name chosen is  left\n",
      "\n",
      "action chosen is  left\n",
      "After get_env_feedback S_ is 0 and R is 0\n",
      "q_predict is  0.0\n",
      "R is 0 and GAMMA is 0.9 and q_table.iloc[S_, :] is left     0.0\n",
      "right    0.0\n",
      "Name: 0, dtype: float64 and q_target will be 0.0\n",
      "S is 1 and A is left and after update q_table.loc[S, A] is 0.000000\n",
      "\n",
      "S is 0 episode is 6 step_counter is 42\n",
      "\n",
      "update_env_else\n",
      "o----T\n",
      " if state_actions is  left     0.0\n",
      "right    0.0\n",
      "Name: 0, dtype: float64  and action_name chosen is  right\n",
      "\n",
      "action chosen is  right\n",
      "After get_env_feedback S_ is 1 and R is 0\n",
      "q_predict is  0.0\n",
      "R is 0 and GAMMA is 0.9 and q_table.iloc[S_, :] is left     0.0\n",
      "right    0.0\n",
      "Name: 1, dtype: float64 and q_target will be 0.0\n",
      "S is 0 and A is right and after update q_table.loc[S, A] is 0.000000\n",
      "\n",
      "S is 1 episode is 6 step_counter is 43\n",
      "\n",
      "update_env_else\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-o---T\n",
      " if state_actions is  left     0.0\n",
      "right    0.0\n",
      "Name: 1, dtype: float64  and action_name chosen is  left\n",
      "\n",
      "action chosen is  left\n",
      "After get_env_feedback S_ is 0 and R is 0\n",
      "q_predict is  0.0\n",
      "R is 0 and GAMMA is 0.9 and q_table.iloc[S_, :] is left     0.0\n",
      "right    0.0\n",
      "Name: 0, dtype: float64 and q_target will be 0.0\n",
      "S is 1 and A is left and after update q_table.loc[S, A] is 0.000000\n",
      "\n",
      "S is 0 episode is 6 step_counter is 44\n",
      "\n",
      "update_env_else\n",
      "o----T\n",
      " if state_actions is  left     0.0\n",
      "right    0.0\n",
      "Name: 0, dtype: float64  and action_name chosen is  right\n",
      "\n",
      "action chosen is  right\n",
      "After get_env_feedback S_ is 1 and R is 0\n",
      "q_predict is  0.0\n",
      "R is 0 and GAMMA is 0.9 and q_table.iloc[S_, :] is left     0.0\n",
      "right    0.0\n",
      "Name: 1, dtype: float64 and q_target will be 0.0\n",
      "S is 0 and A is right and after update q_table.loc[S, A] is 0.000000\n",
      "\n",
      "S is 1 episode is 6 step_counter is 45\n",
      "\n",
      "update_env_else\n",
      "-o---T\n",
      " if state_actions is  left     0.0\n",
      "right    0.0\n",
      "Name: 1, dtype: float64  and action_name chosen is  right\n",
      "\n",
      "action chosen is  right\n",
      "After get_env_feedback S_ is 2 and R is 0\n",
      "q_predict is  0.0\n",
      "R is 0 and GAMMA is 0.9 and q_table.iloc[S_, :] is left     0.0\n",
      "right    0.0\n",
      "Name: 2, dtype: float64 and q_target will be 0.0\n",
      "S is 1 and A is right and after update q_table.loc[S, A] is 0.000000\n",
      "\n",
      "S is 2 episode is 6 step_counter is 46\n",
      "\n",
      "update_env_else\n",
      "--o--T\n",
      " if state_actions is  left     0.0\n",
      "right    0.0\n",
      "Name: 2, dtype: float64  and action_name chosen is  left\n",
      "\n",
      "action chosen is  left\n",
      "After get_env_feedback S_ is 1 and R is 0\n",
      "q_predict is  0.0\n",
      "R is 0 and GAMMA is 0.9 and q_table.iloc[S_, :] is left     0.0\n",
      "right    0.0\n",
      "Name: 1, dtype: float64 and q_target will be 0.0\n",
      "S is 2 and A is left and after update q_table.loc[S, A] is 0.000000\n",
      "\n",
      "S is 1 episode is 6 step_counter is 47\n",
      "\n",
      "update_env_else\n",
      "-o---T\n",
      " if state_actions is  left     0.0\n",
      "right    0.0\n",
      "Name: 1, dtype: float64  and action_name chosen is  left\n",
      "\n",
      "action chosen is  left\n",
      "After get_env_feedback S_ is 0 and R is 0\n",
      "q_predict is  0.0\n",
      "R is 0 and GAMMA is 0.9 and q_table.iloc[S_, :] is left     0.0\n",
      "right    0.0\n",
      "Name: 0, dtype: float64 and q_target will be 0.0\n",
      "S is 1 and A is left and after update q_table.loc[S, A] is 0.000000\n",
      "\n",
      "S is 0 episode is 6 step_counter is 48\n",
      "\n",
      "update_env_else\n",
      "o----T\n",
      " if state_actions is  left     0.0\n",
      "right    0.0\n",
      "Name: 0, dtype: float64  and action_name chosen is  right\n",
      "\n",
      "action chosen is  right\n",
      "After get_env_feedback S_ is 1 and R is 0\n",
      "q_predict is  0.0\n",
      "R is 0 and GAMMA is 0.9 and q_table.iloc[S_, :] is left     0.0\n",
      "right    0.0\n",
      "Name: 1, dtype: float64 and q_target will be 0.0\n",
      "S is 0 and A is right and after update q_table.loc[S, A] is 0.000000\n",
      "\n",
      "S is 1 episode is 6 step_counter is 49\n",
      "\n",
      "update_env_else\n",
      "-o---T\n",
      " if state_actions is  left     0.0\n",
      "right    0.0\n",
      "Name: 1, dtype: float64  and action_name chosen is  left\n",
      "\n",
      "action chosen is  left\n",
      "After get_env_feedback S_ is 0 and R is 0\n",
      "q_predict is  0.0\n",
      "R is 0 and GAMMA is 0.9 and q_table.iloc[S_, :] is left     0.0\n",
      "right    0.0\n",
      "Name: 0, dtype: float64 and q_target will be 0.0\n",
      "S is 1 and A is left and after update q_table.loc[S, A] is 0.000000\n",
      "\n",
      "S is 0 episode is 6 step_counter is 50\n",
      "\n",
      "update_env_else\n",
      "o----T\n",
      " if state_actions is  left     0.0\n",
      "right    0.0\n",
      "Name: 0, dtype: float64  and action_name chosen is  right\n",
      "\n",
      "action chosen is  right\n",
      "After get_env_feedback S_ is 1 and R is 0\n",
      "q_predict is  0.0\n",
      "R is 0 and GAMMA is 0.9 and q_table.iloc[S_, :] is left     0.0\n",
      "right    0.0\n",
      "Name: 1, dtype: float64 and q_target will be 0.0\n",
      "S is 0 and A is right and after update q_table.loc[S, A] is 0.000000\n",
      "\n",
      "S is 1 episode is 6 step_counter is 51\n",
      "\n",
      "update_env_else\n",
      "-o---T\n",
      " if state_actions is  left     0.0\n",
      "right    0.0\n",
      "Name: 1, dtype: float64  and action_name chosen is  right\n",
      "\n",
      "action chosen is  right\n",
      "After get_env_feedback S_ is 2 and R is 0\n",
      "q_predict is  0.0\n",
      "R is 0 and GAMMA is 0.9 and q_table.iloc[S_, :] is left     0.0\n",
      "right    0.0\n",
      "Name: 2, dtype: float64 and q_target will be 0.0\n",
      "S is 1 and A is right and after update q_table.loc[S, A] is 0.000000\n",
      "\n",
      "S is 2 episode is 6 step_counter is 52\n",
      "\n",
      "update_env_else\n",
      "--o--T\n",
      " if state_actions is  left     0.0\n",
      "right    0.0\n",
      "Name: 2, dtype: float64  and action_name chosen is  left\n",
      "\n",
      "action chosen is  left\n",
      "After get_env_feedback S_ is 1 and R is 0\n",
      "q_predict is  0.0\n",
      "R is 0 and GAMMA is 0.9 and q_table.iloc[S_, :] is left     0.0\n",
      "right    0.0\n",
      "Name: 1, dtype: float64 and q_target will be 0.0\n",
      "S is 2 and A is left and after update q_table.loc[S, A] is 0.000000\n",
      "\n",
      "S is 1 episode is 6 step_counter is 53\n",
      "\n",
      "update_env_else\n",
      "-o---T\n",
      " if state_actions is  left     0.0\n",
      "right    0.0\n",
      "Name: 1, dtype: float64  and action_name chosen is  left\n",
      "\n",
      "action chosen is  left\n",
      "After get_env_feedback S_ is 0 and R is 0\n",
      "q_predict is  0.0\n",
      "R is 0 and GAMMA is 0.9 and q_table.iloc[S_, :] is left     0.0\n",
      "right    0.0\n",
      "Name: 0, dtype: float64 and q_target will be 0.0\n",
      "S is 1 and A is left and after update q_table.loc[S, A] is 0.000000\n",
      "\n",
      "S is 0 episode is 6 step_counter is 54\n",
      "\n",
      "update_env_else\n",
      "o----T\n",
      " if state_actions is  left     0.0\n",
      "right    0.0\n",
      "Name: 0, dtype: float64  and action_name chosen is  right\n",
      "\n",
      "action chosen is  right\n",
      "After get_env_feedback S_ is 1 and R is 0\n",
      "q_predict is  0.0\n",
      "R is 0 and GAMMA is 0.9 and q_table.iloc[S_, :] is left     0.0\n",
      "right    0.0\n",
      "Name: 1, dtype: float64 and q_target will be 0.0\n",
      "S is 0 and A is right and after update q_table.loc[S, A] is 0.000000\n",
      "\n",
      "S is 1 episode is 6 step_counter is 55\n",
      "\n",
      "update_env_else\n",
      "-o---T\n",
      " if state_actions is  left     0.0\n",
      "right    0.0\n",
      "Name: 1, dtype: float64  and action_name chosen is  right\n",
      "\n",
      "action chosen is  right\n",
      "After get_env_feedback S_ is 2 and R is 0\n",
      "q_predict is  0.0\n",
      "R is 0 and GAMMA is 0.9 and q_table.iloc[S_, :] is left     0.0\n",
      "right    0.0\n",
      "Name: 2, dtype: float64 and q_target will be 0.0\n",
      "S is 1 and A is right and after update q_table.loc[S, A] is 0.000000\n",
      "\n",
      "S is 2 episode is 6 step_counter is 56\n",
      "\n",
      "update_env_else\n",
      "--o--T\n",
      " if state_actions is  left     0.0\n",
      "right    0.0\n",
      "Name: 2, dtype: float64  and action_name chosen is  right\n",
      "\n",
      "action chosen is  right\n",
      "After get_env_feedback S_ is 3 and R is 0\n",
      "q_predict is  0.0\n",
      "R is 0 and GAMMA is 0.9 and q_table.iloc[S_, :] is left     0.0\n",
      "right    0.0\n",
      "Name: 3, dtype: float64 and q_target will be 0.0\n",
      "S is 2 and A is right and after update q_table.loc[S, A] is 0.000000\n",
      "\n",
      "S is 3 episode is 6 step_counter is 57\n",
      "\n",
      "update_env_else\n",
      "---o-T\n",
      " if state_actions is  left     0.0\n",
      "right    0.0\n",
      "Name: 3, dtype: float64  and action_name chosen is  right\n",
      "\n",
      "action chosen is  right\n",
      "After get_env_feedback S_ is 4 and R is 0\n",
      "q_predict is  0.0\n",
      "R is 0 and GAMMA is 0.9 and q_table.iloc[S_, :] is left     0.0\n",
      "right    0.0\n",
      "Name: 4, dtype: float64 and q_target will be 0.0\n",
      "S is 3 and A is right and after update q_table.loc[S, A] is 0.000000\n",
      "\n",
      "S is 4 episode is 6 step_counter is 58\n",
      "\n",
      "update_env_else\n",
      "----oT\n",
      " if state_actions is  left     0.0\n",
      "right    0.0\n",
      "Name: 4, dtype: float64  and action_name chosen is  right\n",
      "\n",
      "action chosen is  right\n",
      "After get_env_feedback S_ is terminal and R is 1\n",
      "q_predict is  0.0\n",
      "S is 4 and A is right and after update q_table.loc[S, A] is 0.000000\n",
      "\n",
      "S is terminal episode is 6 step_counter is 59\n",
      "\n",
      "update_env_if\n",
      "Episode 7: total_steps = 59\n",
      "update_env_if\n",
      "                                \n",
      "S is 0 episode is 7 step_counter is 0\n",
      "\n",
      "update_env_else\n",
      "o----T\n",
      " if state_actions is  left     0.0\n",
      "right    0.0\n",
      "Name: 0, dtype: float64  and action_name chosen is  right\n",
      "\n",
      "action chosen is  right\n",
      "After get_env_feedback S_ is 1 and R is 0\n",
      "q_predict is  0.0\n",
      "R is 0 and GAMMA is 0.9 and q_table.iloc[S_, :] is left     0.0\n",
      "right    0.0\n",
      "Name: 1, dtype: float64 and q_target will be 0.0\n",
      "S is 0 and A is right and after update q_table.loc[S, A] is 0.000000\n",
      "\n",
      "S is 1 episode is 7 step_counter is 1\n",
      "\n",
      "update_env_else\n",
      "-o---T\n",
      " if state_actions is  left     0.0\n",
      "right    0.0\n",
      "Name: 1, dtype: float64  and action_name chosen is  right\n",
      "\n",
      "action chosen is  right\n",
      "After get_env_feedback S_ is 2 and R is 0\n",
      "q_predict is  0.0\n",
      "R is 0 and GAMMA is 0.9 and q_table.iloc[S_, :] is left     0.0\n",
      "right    0.0\n",
      "Name: 2, dtype: float64 and q_target will be 0.0\n",
      "S is 1 and A is right and after update q_table.loc[S, A] is 0.000000\n",
      "\n",
      "S is 2 episode is 7 step_counter is 2\n",
      "\n",
      "update_env_else\n",
      "--o--T\n",
      " if state_actions is  left     0.0\n",
      "right    0.0\n",
      "Name: 2, dtype: float64  and action_name chosen is  left\n",
      "\n",
      "action chosen is  left\n",
      "After get_env_feedback S_ is 1 and R is 0\n",
      "q_predict is  0.0\n",
      "R is 0 and GAMMA is 0.9 and q_table.iloc[S_, :] is left     0.0\n",
      "right    0.0\n",
      "Name: 1, dtype: float64 and q_target will be 0.0\n",
      "S is 2 and A is left and after update q_table.loc[S, A] is 0.000000\n",
      "\n",
      "S is 1 episode is 7 step_counter is 3\n",
      "\n",
      "update_env_else\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-o---T\n",
      " if state_actions is  left     0.0\n",
      "right    0.0\n",
      "Name: 1, dtype: float64  and action_name chosen is  left\n",
      "\n",
      "action chosen is  left\n",
      "After get_env_feedback S_ is 0 and R is 0\n",
      "q_predict is  0.0\n",
      "R is 0 and GAMMA is 0.9 and q_table.iloc[S_, :] is left     0.0\n",
      "right    0.0\n",
      "Name: 0, dtype: float64 and q_target will be 0.0\n",
      "S is 1 and A is left and after update q_table.loc[S, A] is 0.000000\n",
      "\n",
      "S is 0 episode is 7 step_counter is 4\n",
      "\n",
      "update_env_else\n",
      "o----T\n",
      " if state_actions is  left     0.0\n",
      "right    0.0\n",
      "Name: 0, dtype: float64  and action_name chosen is  right\n",
      "\n",
      "action chosen is  right\n",
      "After get_env_feedback S_ is 1 and R is 0\n",
      "q_predict is  0.0\n",
      "R is 0 and GAMMA is 0.9 and q_table.iloc[S_, :] is left     0.0\n",
      "right    0.0\n",
      "Name: 1, dtype: float64 and q_target will be 0.0\n",
      "S is 0 and A is right and after update q_table.loc[S, A] is 0.000000\n",
      "\n",
      "S is 1 episode is 7 step_counter is 5\n",
      "\n",
      "update_env_else\n",
      "-o---T\n",
      " if state_actions is  left     0.0\n",
      "right    0.0\n",
      "Name: 1, dtype: float64  and action_name chosen is  right\n",
      "\n",
      "action chosen is  right\n",
      "After get_env_feedback S_ is 2 and R is 0\n",
      "q_predict is  0.0\n",
      "R is 0 and GAMMA is 0.9 and q_table.iloc[S_, :] is left     0.0\n",
      "right    0.0\n",
      "Name: 2, dtype: float64 and q_target will be 0.0\n",
      "S is 1 and A is right and after update q_table.loc[S, A] is 0.000000\n",
      "\n",
      "S is 2 episode is 7 step_counter is 6\n",
      "\n",
      "update_env_else\n",
      "--o--T\n",
      " if state_actions is  left     0.0\n",
      "right    0.0\n",
      "Name: 2, dtype: float64  and action_name chosen is  left\n",
      "\n",
      "action chosen is  left\n",
      "After get_env_feedback S_ is 1 and R is 0\n",
      "q_predict is  0.0\n",
      "R is 0 and GAMMA is 0.9 and q_table.iloc[S_, :] is left     0.0\n",
      "right    0.0\n",
      "Name: 1, dtype: float64 and q_target will be 0.0\n",
      "S is 2 and A is left and after update q_table.loc[S, A] is 0.000000\n",
      "\n",
      "S is 1 episode is 7 step_counter is 7\n",
      "\n",
      "update_env_else\n",
      "-o---T\n",
      " if state_actions is  left     0.0\n",
      "right    0.0\n",
      "Name: 1, dtype: float64  and action_name chosen is  left\n",
      "\n",
      "action chosen is  left\n",
      "After get_env_feedback S_ is 0 and R is 0\n",
      "q_predict is  0.0\n",
      "R is 0 and GAMMA is 0.9 and q_table.iloc[S_, :] is left     0.0\n",
      "right    0.0\n",
      "Name: 0, dtype: float64 and q_target will be 0.0\n",
      "S is 1 and A is left and after update q_table.loc[S, A] is 0.000000\n",
      "\n",
      "S is 0 episode is 7 step_counter is 8\n",
      "\n",
      "update_env_else\n",
      "o----T\n",
      " if state_actions is  left     0.0\n",
      "right    0.0\n",
      "Name: 0, dtype: float64  and action_name chosen is  left\n",
      "\n",
      "action chosen is  left\n",
      "After get_env_feedback S_ is 0 and R is 0\n",
      "q_predict is  0.0\n",
      "R is 0 and GAMMA is 0.9 and q_table.iloc[S_, :] is left     0.0\n",
      "right    0.0\n",
      "Name: 0, dtype: float64 and q_target will be 0.0\n",
      "S is 0 and A is left and after update q_table.loc[S, A] is 0.000000\n",
      "\n",
      "S is 0 episode is 7 step_counter is 9\n",
      "\n",
      "update_env_else\n",
      "o----T\n",
      " if state_actions is  left     0.0\n",
      "right    0.0\n",
      "Name: 0, dtype: float64  and action_name chosen is  right\n",
      "\n",
      "action chosen is  right\n",
      "After get_env_feedback S_ is 1 and R is 0\n",
      "q_predict is  0.0\n",
      "R is 0 and GAMMA is 0.9 and q_table.iloc[S_, :] is left     0.0\n",
      "right    0.0\n",
      "Name: 1, dtype: float64 and q_target will be 0.0\n",
      "S is 0 and A is right and after update q_table.loc[S, A] is 0.000000\n",
      "\n",
      "S is 1 episode is 7 step_counter is 10\n",
      "\n",
      "update_env_else\n",
      "-o---T\n",
      " if state_actions is  left     0.0\n",
      "right    0.0\n",
      "Name: 1, dtype: float64  and action_name chosen is  right\n",
      "\n",
      "action chosen is  right\n",
      "After get_env_feedback S_ is 2 and R is 0\n",
      "q_predict is  0.0\n",
      "R is 0 and GAMMA is 0.9 and q_table.iloc[S_, :] is left     0.0\n",
      "right    0.0\n",
      "Name: 2, dtype: float64 and q_target will be 0.0\n",
      "S is 1 and A is right and after update q_table.loc[S, A] is 0.000000\n",
      "\n",
      "S is 2 episode is 7 step_counter is 11\n",
      "\n",
      "update_env_else\n",
      "--o--T\n",
      " if state_actions is  left     0.0\n",
      "right    0.0\n",
      "Name: 2, dtype: float64  and action_name chosen is  right\n",
      "\n",
      "action chosen is  right\n",
      "After get_env_feedback S_ is 3 and R is 0\n",
      "q_predict is  0.0\n",
      "R is 0 and GAMMA is 0.9 and q_table.iloc[S_, :] is left     0.0\n",
      "right    0.0\n",
      "Name: 3, dtype: float64 and q_target will be 0.0\n",
      "S is 2 and A is right and after update q_table.loc[S, A] is 0.000000\n",
      "\n",
      "S is 3 episode is 7 step_counter is 12\n",
      "\n",
      "update_env_else\n",
      "---o-T\n",
      " if state_actions is  left     0.0\n",
      "right    0.0\n",
      "Name: 3, dtype: float64  and action_name chosen is  right\n",
      "\n",
      "action chosen is  right\n",
      "After get_env_feedback S_ is 4 and R is 0\n",
      "q_predict is  0.0\n",
      "R is 0 and GAMMA is 0.9 and q_table.iloc[S_, :] is left     0.0\n",
      "right    0.0\n",
      "Name: 4, dtype: float64 and q_target will be 0.0\n",
      "S is 3 and A is right and after update q_table.loc[S, A] is 0.000000\n",
      "\n",
      "S is 4 episode is 7 step_counter is 13\n",
      "\n",
      "update_env_else\n",
      "----oT\n",
      " if state_actions is  left     0.0\n",
      "right    0.0\n",
      "Name: 4, dtype: float64  and action_name chosen is  right\n",
      "\n",
      "action chosen is  right\n",
      "After get_env_feedback S_ is terminal and R is 1\n",
      "q_predict is  0.0\n",
      "S is 4 and A is right and after update q_table.loc[S, A] is 0.000000\n",
      "\n",
      "S is terminal episode is 7 step_counter is 14\n",
      "\n",
      "update_env_if\n",
      "Episode 8: total_steps = 14\n",
      "update_env_if\n",
      "                                \n",
      "S is 0 episode is 8 step_counter is 0\n",
      "\n",
      "update_env_else\n",
      "o----T\n",
      " if state_actions is  left     0.0\n",
      "right    0.0\n",
      "Name: 0, dtype: float64  and action_name chosen is  left\n",
      "\n",
      "action chosen is  left\n",
      "After get_env_feedback S_ is 0 and R is 0\n",
      "q_predict is  0.0\n",
      "R is 0 and GAMMA is 0.9 and q_table.iloc[S_, :] is left     0.0\n",
      "right    0.0\n",
      "Name: 0, dtype: float64 and q_target will be 0.0\n",
      "S is 0 and A is left and after update q_table.loc[S, A] is 0.000000\n",
      "\n",
      "S is 0 episode is 8 step_counter is 1\n",
      "\n",
      "update_env_else\n",
      "o----T\n",
      " if state_actions is  left     0.0\n",
      "right    0.0\n",
      "Name: 0, dtype: float64  and action_name chosen is  right\n",
      "\n",
      "action chosen is  right\n",
      "After get_env_feedback S_ is 1 and R is 0\n",
      "q_predict is  0.0\n",
      "R is 0 and GAMMA is 0.9 and q_table.iloc[S_, :] is left     0.0\n",
      "right    0.0\n",
      "Name: 1, dtype: float64 and q_target will be 0.0\n",
      "S is 0 and A is right and after update q_table.loc[S, A] is 0.000000\n",
      "\n",
      "S is 1 episode is 8 step_counter is 2\n",
      "\n",
      "update_env_else\n",
      "-o---T\n",
      " if state_actions is  left     0.0\n",
      "right    0.0\n",
      "Name: 1, dtype: float64  and action_name chosen is  right\n",
      "\n",
      "action chosen is  right\n",
      "After get_env_feedback S_ is 2 and R is 0\n",
      "q_predict is  0.0\n",
      "R is 0 and GAMMA is 0.9 and q_table.iloc[S_, :] is left     0.0\n",
      "right    0.0\n",
      "Name: 2, dtype: float64 and q_target will be 0.0\n",
      "S is 1 and A is right and after update q_table.loc[S, A] is 0.000000\n",
      "\n",
      "S is 2 episode is 8 step_counter is 3\n",
      "\n",
      "update_env_else\n",
      "--o--T\n",
      " if state_actions is  left     0.0\n",
      "right    0.0\n",
      "Name: 2, dtype: float64  and action_name chosen is  right\n",
      "\n",
      "action chosen is  right\n",
      "After get_env_feedback S_ is 3 and R is 0\n",
      "q_predict is  0.0\n",
      "R is 0 and GAMMA is 0.9 and q_table.iloc[S_, :] is left     0.0\n",
      "right    0.0\n",
      "Name: 3, dtype: float64 and q_target will be 0.0\n",
      "S is 2 and A is right and after update q_table.loc[S, A] is 0.000000\n",
      "\n",
      "S is 3 episode is 8 step_counter is 4\n",
      "\n",
      "update_env_else\n",
      "---o-T\n",
      " if state_actions is  left     0.0\n",
      "right    0.0\n",
      "Name: 3, dtype: float64  and action_name chosen is  right\n",
      "\n",
      "action chosen is  right\n",
      "After get_env_feedback S_ is 4 and R is 0\n",
      "q_predict is  0.0\n",
      "R is 0 and GAMMA is 0.9 and q_table.iloc[S_, :] is left     0.0\n",
      "right    0.0\n",
      "Name: 4, dtype: float64 and q_target will be 0.0\n",
      "S is 3 and A is right and after update q_table.loc[S, A] is 0.000000\n",
      "\n",
      "S is 4 episode is 8 step_counter is 5\n",
      "\n",
      "update_env_else\n",
      "----oT\n",
      " if state_actions is  left     0.0\n",
      "right    0.0\n",
      "Name: 4, dtype: float64  and action_name chosen is  right\n",
      "\n",
      "action chosen is  right\n",
      "After get_env_feedback S_ is terminal and R is 1\n",
      "q_predict is  0.0\n",
      "S is 4 and A is right and after update q_table.loc[S, A] is 0.000000\n",
      "\n",
      "S is terminal episode is 8 step_counter is 6\n",
      "\n",
      "update_env_if\n",
      "Episode 9: total_steps = 6\n",
      "update_env_if\n",
      "                                \n",
      "S is 0 episode is 9 step_counter is 0\n",
      "\n",
      "update_env_else\n",
      "o----T\n",
      " if state_actions is  left     0.0\n",
      "right    0.0\n",
      "Name: 0, dtype: float64  and action_name chosen is  left\n",
      "\n",
      "action chosen is  left\n",
      "After get_env_feedback S_ is 0 and R is 0\n",
      "q_predict is  0.0\n",
      "R is 0 and GAMMA is 0.9 and q_table.iloc[S_, :] is left     0.0\n",
      "right    0.0\n",
      "Name: 0, dtype: float64 and q_target will be 0.0\n",
      "S is 0 and A is left and after update q_table.loc[S, A] is 0.000000\n",
      "\n",
      "S is 0 episode is 9 step_counter is 1\n",
      "\n",
      "update_env_else\n",
      "o----T\n",
      " if state_actions is  left     0.0\n",
      "right    0.0\n",
      "Name: 0, dtype: float64  and action_name chosen is  left\n",
      "\n",
      "action chosen is  left\n",
      "After get_env_feedback S_ is 0 and R is 0\n",
      "q_predict is  0.0\n",
      "R is 0 and GAMMA is 0.9 and q_table.iloc[S_, :] is left     0.0\n",
      "right    0.0\n",
      "Name: 0, dtype: float64 and q_target will be 0.0\n",
      "S is 0 and A is left and after update q_table.loc[S, A] is 0.000000\n",
      "\n",
      "S is 0 episode is 9 step_counter is 2\n",
      "\n",
      "update_env_else\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "o----T\n",
      " if state_actions is  left     0.0\n",
      "right    0.0\n",
      "Name: 0, dtype: float64  and action_name chosen is  right\n",
      "\n",
      "action chosen is  right\n",
      "After get_env_feedback S_ is 1 and R is 0\n",
      "q_predict is  0.0\n",
      "R is 0 and GAMMA is 0.9 and q_table.iloc[S_, :] is left     0.0\n",
      "right    0.0\n",
      "Name: 1, dtype: float64 and q_target will be 0.0\n",
      "S is 0 and A is right and after update q_table.loc[S, A] is 0.000000\n",
      "\n",
      "S is 1 episode is 9 step_counter is 3\n",
      "\n",
      "update_env_else\n",
      "-o---T\n",
      " if state_actions is  left     0.0\n",
      "right    0.0\n",
      "Name: 1, dtype: float64  and action_name chosen is  left\n",
      "\n",
      "action chosen is  left\n",
      "After get_env_feedback S_ is 0 and R is 0\n",
      "q_predict is  0.0\n",
      "R is 0 and GAMMA is 0.9 and q_table.iloc[S_, :] is left     0.0\n",
      "right    0.0\n",
      "Name: 0, dtype: float64 and q_target will be 0.0\n",
      "S is 1 and A is left and after update q_table.loc[S, A] is 0.000000\n",
      "\n",
      "S is 0 episode is 9 step_counter is 4\n",
      "\n",
      "update_env_else\n",
      "o----T\n",
      " if state_actions is  left     0.0\n",
      "right    0.0\n",
      "Name: 0, dtype: float64  and action_name chosen is  right\n",
      "\n",
      "action chosen is  right\n",
      "After get_env_feedback S_ is 1 and R is 0\n",
      "q_predict is  0.0\n",
      "R is 0 and GAMMA is 0.9 and q_table.iloc[S_, :] is left     0.0\n",
      "right    0.0\n",
      "Name: 1, dtype: float64 and q_target will be 0.0\n",
      "S is 0 and A is right and after update q_table.loc[S, A] is 0.000000\n",
      "\n",
      "S is 1 episode is 9 step_counter is 5\n",
      "\n",
      "update_env_else\n",
      "-o---T\n",
      " if state_actions is  left     0.0\n",
      "right    0.0\n",
      "Name: 1, dtype: float64  and action_name chosen is  right\n",
      "\n",
      "action chosen is  right\n",
      "After get_env_feedback S_ is 2 and R is 0\n",
      "q_predict is  0.0\n",
      "R is 0 and GAMMA is 0.9 and q_table.iloc[S_, :] is left     0.0\n",
      "right    0.0\n",
      "Name: 2, dtype: float64 and q_target will be 0.0\n",
      "S is 1 and A is right and after update q_table.loc[S, A] is 0.000000\n",
      "\n",
      "S is 2 episode is 9 step_counter is 6\n",
      "\n",
      "update_env_else\n",
      "--o--T\n",
      " if state_actions is  left     0.0\n",
      "right    0.0\n",
      "Name: 2, dtype: float64  and action_name chosen is  left\n",
      "\n",
      "action chosen is  left\n",
      "After get_env_feedback S_ is 1 and R is 0\n",
      "q_predict is  0.0\n",
      "R is 0 and GAMMA is 0.9 and q_table.iloc[S_, :] is left     0.0\n",
      "right    0.0\n",
      "Name: 1, dtype: float64 and q_target will be 0.0\n",
      "S is 2 and A is left and after update q_table.loc[S, A] is 0.000000\n",
      "\n",
      "S is 1 episode is 9 step_counter is 7\n",
      "\n",
      "update_env_else\n",
      "-o---T\n",
      " if state_actions is  left     0.0\n",
      "right    0.0\n",
      "Name: 1, dtype: float64  and action_name chosen is  left\n",
      "\n",
      "action chosen is  left\n",
      "After get_env_feedback S_ is 0 and R is 0\n",
      "q_predict is  0.0\n",
      "R is 0 and GAMMA is 0.9 and q_table.iloc[S_, :] is left     0.0\n",
      "right    0.0\n",
      "Name: 0, dtype: float64 and q_target will be 0.0\n",
      "S is 1 and A is left and after update q_table.loc[S, A] is 0.000000\n",
      "\n",
      "S is 0 episode is 9 step_counter is 8\n",
      "\n",
      "update_env_else\n",
      "o----T\n",
      " if state_actions is  left     0.0\n",
      "right    0.0\n",
      "Name: 0, dtype: float64  and action_name chosen is  right\n",
      "\n",
      "action chosen is  right\n",
      "After get_env_feedback S_ is 1 and R is 0\n",
      "q_predict is  0.0\n",
      "R is 0 and GAMMA is 0.9 and q_table.iloc[S_, :] is left     0.0\n",
      "right    0.0\n",
      "Name: 1, dtype: float64 and q_target will be 0.0\n",
      "S is 0 and A is right and after update q_table.loc[S, A] is 0.000000\n",
      "\n",
      "S is 1 episode is 9 step_counter is 9\n",
      "\n",
      "update_env_else\n",
      "-o---T\n",
      " if state_actions is  left     0.0\n",
      "right    0.0\n",
      "Name: 1, dtype: float64  and action_name chosen is  left\n",
      "\n",
      "action chosen is  left\n",
      "After get_env_feedback S_ is 0 and R is 0\n",
      "q_predict is  0.0\n",
      "R is 0 and GAMMA is 0.9 and q_table.iloc[S_, :] is left     0.0\n",
      "right    0.0\n",
      "Name: 0, dtype: float64 and q_target will be 0.0\n",
      "S is 1 and A is left and after update q_table.loc[S, A] is 0.000000\n",
      "\n",
      "S is 0 episode is 9 step_counter is 10\n",
      "\n",
      "update_env_else\n",
      "o----T\n",
      " if state_actions is  left     0.0\n",
      "right    0.0\n",
      "Name: 0, dtype: float64  and action_name chosen is  right\n",
      "\n",
      "action chosen is  right\n",
      "After get_env_feedback S_ is 1 and R is 0\n",
      "q_predict is  0.0\n",
      "R is 0 and GAMMA is 0.9 and q_table.iloc[S_, :] is left     0.0\n",
      "right    0.0\n",
      "Name: 1, dtype: float64 and q_target will be 0.0\n",
      "S is 0 and A is right and after update q_table.loc[S, A] is 0.000000\n",
      "\n",
      "S is 1 episode is 9 step_counter is 11\n",
      "\n",
      "update_env_else\n",
      "-o---T\n",
      " if state_actions is  left     0.0\n",
      "right    0.0\n",
      "Name: 1, dtype: float64  and action_name chosen is  right\n",
      "\n",
      "action chosen is  right\n",
      "After get_env_feedback S_ is 2 and R is 0\n",
      "q_predict is  0.0\n",
      "R is 0 and GAMMA is 0.9 and q_table.iloc[S_, :] is left     0.0\n",
      "right    0.0\n",
      "Name: 2, dtype: float64 and q_target will be 0.0\n",
      "S is 1 and A is right and after update q_table.loc[S, A] is 0.000000\n",
      "\n",
      "S is 2 episode is 9 step_counter is 12\n",
      "\n",
      "update_env_else\n",
      "--o--T\n",
      " if state_actions is  left     0.0\n",
      "right    0.0\n",
      "Name: 2, dtype: float64  and action_name chosen is  right\n",
      "\n",
      "action chosen is  right\n",
      "After get_env_feedback S_ is 3 and R is 0\n",
      "q_predict is  0.0\n",
      "R is 0 and GAMMA is 0.9 and q_table.iloc[S_, :] is left     0.0\n",
      "right    0.0\n",
      "Name: 3, dtype: float64 and q_target will be 0.0\n",
      "S is 2 and A is right and after update q_table.loc[S, A] is 0.000000\n",
      "\n",
      "S is 3 episode is 9 step_counter is 13\n",
      "\n",
      "update_env_else\n",
      "---o-T\n",
      " if state_actions is  left     0.0\n",
      "right    0.0\n",
      "Name: 3, dtype: float64  and action_name chosen is  right\n",
      "\n",
      "action chosen is  right\n",
      "After get_env_feedback S_ is 4 and R is 0\n",
      "q_predict is  0.0\n",
      "R is 0 and GAMMA is 0.9 and q_table.iloc[S_, :] is left     0.0\n",
      "right    0.0\n",
      "Name: 4, dtype: float64 and q_target will be 0.0\n",
      "S is 3 and A is right and after update q_table.loc[S, A] is 0.000000\n",
      "\n",
      "S is 4 episode is 9 step_counter is 14\n",
      "\n",
      "update_env_else\n",
      "----oT\n",
      " if state_actions is  left     0.0\n",
      "right    0.0\n",
      "Name: 4, dtype: float64  and action_name chosen is  right\n",
      "\n",
      "action chosen is  right\n",
      "After get_env_feedback S_ is terminal and R is 1\n",
      "q_predict is  0.0\n",
      "S is 4 and A is right and after update q_table.loc[S, A] is 0.000000\n",
      "\n",
      "S is terminal episode is 9 step_counter is 15\n",
      "\n",
      "update_env_if\n",
      "Episode 10: total_steps = 15\n",
      "update_env_if\n",
      "                                   left  right\n",
      "0   0.0    0.0\n",
      "1   0.0    0.0\n",
      "2   0.0    0.0\n",
      "3   0.0    0.0\n",
      "4   0.0    0.0\n",
      "5   0.0    0.0\n"
     ]
    }
   ],
   "source": [
    "print(rl())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "0  0.000000  0.004320\n",
    "1  0.000000  0.025005\n",
    "2  0.000030  0.111241\n",
    "3  0.000000  0.368750\n",
    "4  0.027621  0.745813\n",
    "5  0.000000  0.000000\n",
    "\n",
    ""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:Anaconda3]",
   "language": "python",
   "name": "conda-env-Anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
